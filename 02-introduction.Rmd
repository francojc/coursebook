# (PART) Foundations {-}

# Overview {-#foundations-overview}

```{r, child="_common.Rmd"}
```

**FOUNDATIONS**

<!-- edit -->
In this section the aims are to (1) provide an overview of quantitative research and their applications, by both highlighting visible applications and notable research in various fields. (2) We will under the hood a bit and consider how quantitative research contributes to language research. (3) I will layout the main types of research and situate quantitative text analysis inside these. Some attention will be given to the historical background to understand how theory (generative and usage-based grammar) has framed and to some degree continues to frame language research. (4) We will discuss how the programmatic approaches to language, which are fundamental for quantitative text analysis, also provide the opportunity to further science through process documentation and research reproducibility. 

<!-- Learning outcomes/ goals

Include these in the Canvas page for the day

-->

# Introduction to text analysis

> Science walks forward on two feet, namely theory and experiment...Sometimes it is one foot which is put forward first, sometimes the other, but continuous progress is only made by the use of both.
> ---[Robert A. Millikan](https://www.nobelprize.org/uploads/2018/06/millikan-lecture.pdf) [-@Millikan1923]

```{block, type="rmdkey"}
The essential questions for this chapter are:

- what is the difference between quantitative and qualitative research? 
- where does text analysis fit in language research?
- what are the benefits of programming approaches to text analysis?
```

<!-- COURSE STRUCTURE
TUTORIALS:

- Git-it: https://github.com/jlord/git-it-electron (interactive app to learn the basics of Git)

SWIRL:

- Variables and vectors
- Workspace

WORKED/ RECIPE:

- Literate programming
- GitHub collaboration

PROJECT:

- Interest statement, annotated references, goal(s), finding(s)
-->


<!-- CHAPTER OUTLINE



-->


In this chapter I will aim to introduce the topic of text analysis and text analytics and frame the approach of this coursebook. The world around us is full of actions and interactions so numerous that it is difficult to really comprehend. Through the lens each individual sees and experiences this world. We gain knowledge about this world and build up heuristic knowledge about how it works and how we do and can interact with it. This happens regardless of your educational background. As humans we are built for this. Our minds process countless sensory inputs many of which never make it to our conscious mind. They underly skills and abilities that we take for granted like being able to predict what will happen if you see someone about to knock a wine glass off a table and onto a concrete floor. You've never seen this object before and this is the first time you've been to this winery, but somehow and from somewhere you 'instinctively' make an effort to warn the would-be-glass-breaker before it is too late. You most likely have not stopped to consider where this predictive knowledge has come from or if you have you may have just chalked it up to 'common sense'. As common as it may be, it is an incredible display of the brain's capacity to monitor your environment, relate the events and observations that take place, and store that information all the time not making a big fuss to tell you conscious mind what it's up to. 

So wait, this is a coursebook on text analytics and language, right? So what does all this have to do with that? Well, there are two points to make that are relevant for framing our journey: (1) the world is full of countless information which unfold in real-time at a scale that is daunting and (2) for all the power of the brain that works so efficiently behind the scene making sense of the world, we are one individual living one life that has a limited view of the world at large. Let me expand on these two points a little more. 

First let's be clear. There is no way for any one to experience all things at all times, i.e. omnipitance. But even extremely reduced slices of reality are still vastly outside of our experiental capacity, at least in real-time. Bringing us closer to the neighborhood of language, we can point out that since the inception of the internet one's ability to experience larger slices of the world have increased. But could you imagine reading, watching, and listening to every file that is accessible on the web (or has been see the Wayback Machine)? Scale this down even further, let's take Wikipedia, the world's largest encyclopedia. Can you imagine reading every wiki entry? As large as a resource such as Wikipedia is, it is still a small fragment of the language that is produced on the web, just the web. Consider that for a moment.

To my second framing point, which is actually two points in one. I made underscored the efficiency of our brain's capacity to make sense of the world. That efficiency comes from some clever evolutionary twists that lead our brain to take in the world but it makes some shortcuts that compress the raw experience into heuristic understanding. What that means is that the brain is not a supercomputer. It does not store every experience in raw form, we do not have access to the records of our experience like we would imagine a computer would have access to the records logged in a database. Where our brains do excel is in making associations and predictions that help us (most of the time) navigate the complex world we inhabit. This point is key --our brains are doing some amazing work, but that work can give us the impression that we understand the world in more detail that we actually do. Let's do a little thought experiment. Close your eyes and think about the last time you saw your best friend. What were they wearing? Can you remember the colors? If your like me, or any other human, you probably will have a pretty confident feeling that you know the answers to these questions and there is a chance you a right. But it has been demonstrated in numerous experiments on human memory that our confidence does not correlate with accuracy. (where were you when ..? JFK, 9/11, ...other example) You've experienced an event, but there is no real reason that we should be our lives on what we experienced. It's a little bit scary, for sure, but the magic is that it works 'good enough' for practical purposes.

So here's the deal: as humans we are (1) clearly unable to experience large swaths of experience by the simple fact that we are individuals living individual lives and (2) the experiences we do live are not recorded with precision. 

What does that mean for our human curiosity about the world around us and our ability to reliably make sense of it? In short it means that we need to approach understanding our world with the tools of science. Science is so powerful because it makes strides to overcome our inherit limitations as humans and bring a complex world into a more digestible perspective. Science starts with question, identifies and collects data, careful selected slices of the complex world, submits this data to analysis through clearly defined and reproducible procedures, and reports the results for others to evaluate. This process is repeated, modifying, and manipulating the procedures, asking new questions and positing new explanations, all in an effort to make inroads to bring the complex into tangible view. 

In essences what science does is attempt to subvert our inherent limitations in understanding by drawing on carefully and purposefully collected slices of experience and letting the analysis of this experience speak, even if it goes against our intuitions (those powerful but sometime spurious heuristics that our brains use to make sense of the world). 

At this point let me bring some terms that have been floating around in the world into our discussion that will helps us place text analysis in context. Unless you've been hiding under a rock you most likely will have encountered the term "data science". This term and the associated work performed by data science praticioners appears to deliniate something new. This is only partly correct. One the one hand data science is still science. Where data science differs is not in the process but really in the emphasis on data, the quantities to be exact. If you are like me learning about science in grade school, you may have visions of white coats, labs, and petri dishes. Modern science hasn't changed in concept, but the access to data has. What once was large slices of experience pale in comparison to the access and ability to collect data in the 21st century. 


---

OK. Here's a thought break. I've started some good ideas in terms of how to frame the world of experience that surrounds us and outlined some of the inherent strengths and limitations that humans have in making sense of this world. At the point that I've left off I've started to meander into science and the process of science a bit too much. I want to steer the conversation more towards the use of science to expand into areas of understanding the world, both in academia and in professional life. One thought I had today in the gym is to introduce the Moneyball case as an example of how traditional, human-based intuition has it's limitations and how approaching behavior and understanding the underlying mechanisms can be enhanced by scientific approaches. Moneyball is a good first case as it is most likely known by students, but it also is a well-documented case of how traditional wisdom was challenged and loss to rigorous data-driven analysis. I thought that I could then jump from this case to the Unibomber manifesto. This brings language into the mix and highlights the inability of individuals to readily detect patterns (the signal) found within texts. The aspect I have in mind is the phrase "Have your cake and eat it to" vs. "Eat your cake and have it to". The FBI was able to build a case against Ted Kasinzki base on this phrase tracing this idiomatic variance to a particular usage which had fallen out of popular usage. 

What I need to reconcile is the trajectory of human-based bias, science, and the expanding use of scientific approaches to a wide variety of areas and professions as the availability of data becomes more widespread and computing resources and statistical approaches more robust. 

Sometime soon after connecting these dots, I want to bring language into focus. Introducing empirical approaches to language study. This discussion should highlight the distinction between experimental data and observational data. I want to contrast the types and trade-offs associated with both approaches. Experimental data is controlled rigorously, recruiting participants, controlling the conditions in which language is presented and behavior is measured. Observational data, one the other hand, is not controlled to the same degree. The data is collected in a way in which language is performed in more natural contexts. Both approaches have advantages and disadvantages. I want to highlight that although this coursebook focuses on observational data, robust understanding of language behavior requires a collaboration between both approaches. 


---




## Quantitative and qualitative research


Quantitative research is on the rise. Whether in industry and academics there are ever fewer domains where quantitative data analysis has not made significant inroads. This growth is in larger part due to the overwhelming increase in the amount of machine readable data available, sometimes referred to as the 'data deluge'. Data alone, however, is not enough. To turn data into insight it takes computing skills, knowledge of statistics, and domain expertise \@ref(fig:intro-data-science-venn). 

- What is it?
  - Nexus between three main areas: statistics, computation, and domain-specific knowledge [Venn diagram](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)

```{r intro-data-science-venn, echo=FALSE, fig.cap='[Venn diagram](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram) by Drew Conway'}
knitr::include_graphics("images/02-introduction/Data_Science_VD.png")
```

The nexus between these three areas has produced some well-known language applications \@ref(fig:intro-language-applications). From the language-capable personal assistant applications, plagarism detection software, machine translation and search, tangible results of quantitative approaches to language are becoming standard fixtures in our lives. 

<!-- Highly visible applications in language -->

```{r intro-language-applications, fig.cap='Well-known language applications', echo = FALSE}
knitr::include_graphics("images/02-introduction/well-known-language-applications.png")
```



