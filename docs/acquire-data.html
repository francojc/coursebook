<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Acquire data | Coursebook</title>
<meta name="author" content="Jerid Francom">
<meta name="description" content="DRAFT  The scariest moment is always just before you start. ―–Stephen King  The essential questions for this chapter are:  What are the most common strategies for acquiring corpus data?  What...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 5 Acquire data | Coursebook">
<meta property="og:type" content="book">
<meta property="og:url" content="https://lin380.github.io/coursebook/acquire-data.html">
<meta property="og:image" content="https://lin380.github.io/coursebook/assets/images/logo.png">
<meta property="og:description" content="DRAFT  The scariest moment is always just before you start. ―–Stephen King  The essential questions for this chapter are:  What are the most common strategies for acquiring corpus data?  What...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Acquire data | Coursebook">
<meta name="twitter:site" content="@jeridfrancom">
<meta name="twitter:description" content="DRAFT  The scariest moment is always just before you start. ―–Stephen King  The essential questions for this chapter are:  What are the most common strategies for acquiring corpus data?  What...">
<meta name="twitter:image" content="https://lin380.github.io/coursebook/assets/images/logo.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Embed Hypothes.is --><script src="https://hypothes.is/embed.js" async></script><!-- Google Analytics --><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-57189160-3', 'auto');
      ga('send', 'pageview');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="assets/bs4.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Text as Data: An introduction to quantitative text analysis and reproducible research with R">Coursebook</a>:
        <small class="text-muted">Text as Data: An introduction to quantitative text analysis and reproducible research with R</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li class="book-part">Foundations</li>
<li><a class="" href="foundations-overview.html">Overview</a></li>
<li><a class="" href="data-language-and-text-analysis.html"><span class="header-section-number">1</span> Data, language, and text analysis</a></li>
<li class="book-part">Orientation</li>
<li><a class="" href="orientation-overview.html">Overview</a></li>
<li><a class="" href="understanding-data.html"><span class="header-section-number">2</span> Understanding data</a></li>
<li><a class="" href="approaching-analysis.html"><span class="header-section-number">3</span> Approaching analysis</a></li>
<li><a class="" href="framing-research.html"><span class="header-section-number">4</span> Framing research</a></li>
<li class="book-part">Preparation</li>
<li><a class="" href="preparation-overview.html">Overview</a></li>
<li><a class="active" href="acquire-data.html"><span class="header-section-number">5</span> Acquire data</a></li>
<li><a class="" href="curate-data.html"><span class="header-section-number">6</span> Curate data</a></li>
<li><a class="" href="transform-data.html"><span class="header-section-number">7</span> Transform data</a></li>
<li class="book-part">Analysis</li>
<li><a class="" href="analysis-overview.html">Overview</a></li>
<li><a class="" href="inference.html"><span class="header-section-number">8</span> Inference</a></li>
<li><a class="" href="prediction.html"><span class="header-section-number">9</span> Prediction</a></li>
<li><a class="" href="exploration.html"><span class="header-section-number">10</span> Exploration</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="section-3.html"><span class="header-section-number">A</span> …</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/lin380/coursebook">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="acquire-data" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Acquire data<a class="anchor" aria-label="anchor" href="#acquire-data"><i class="fas fa-link"></i></a>
</h1>
<p style="font-weight:bold; color:red;">
DRAFT
</p>
<blockquote>
<p>The scariest moment is always just before you start.</p>
<p>―–Stephen King</p>
</blockquote>
<div class="rmdkey">
<p>
The essential questions for this chapter are:
</p>
<ul>
<li>
What are the most common strategies for acquiring corpus data?
</li>
<li>
What programmatic steps can we take to ensure the acquisition process is reproducible?
</li>
<li>
What is the importance of documenting data?
</li>
</ul>
</div>
<!-- COURSE STRUCTURE

TUTORIALS:

- Primers: 
  - Introduction to Iteration: https://rstudio.cloud/learn/primers/5.1
  - Write Functions: https://rstudio.cloud/learn/primers/6
    - Function basics
    - How to Write a Function
    - Arguments

SWIRL:

- ...

WORKED/ RECIPE:

- ...

PROJECT:

- ...

GOALS:

...

-->
<p>There are three main ways to acquire corpus data using R that I will introduce you to: <strong>downloads</strong>, <strong>APIs</strong>, and <strong>web scraping</strong>. In this chapter we will start by manual and programmatically downloading a corpus as it is the most straightforward process for the novice R programmer and typically incurs the least number of steps. Along the way I will introduce some key R coding concepts including control statements and custom functions. Next I will cover using R packages to interface with APIs, both open-access and authentication-based. APIs will require us to delve into more detail about R objects and custom functions. Finally acquiring data from the web via webscraping is the most idiosyncratic and involves both knowledge of the web, more sophisticated R skills, and often some clever hacking skills. I will start with a crash course on the structure of web documents (HTML) and then scale up to a real-world example. To round out the chapter we will cover the process of ensuring that our data is documented in such a way as to provide sufficient information to understand its key sampling characteristics and the source from which it was drawn.</p>
<div id="downloads" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Downloads<a class="anchor" aria-label="anchor" href="#downloads"><i class="fas fa-link"></i></a>
</h2>
<div id="manual" class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> Manual<a class="anchor" aria-label="anchor" href="#manual"><i class="fas fa-link"></i></a>
</h3>
<p>The first acquisition method I will cover here is inherently non-reproducible from the standpoint that the programming implementation cannot acquire the data based solely on running the project code itself. In other words, it requires manual intervention. Manual downloads are typical for data resources which are not openly accessible on the public facing web. These can be resources that require institutional or private licensing (<a href="https://www.ldc.upenn.edu/">Language Data Consortium</a>, <a href="http://ice-corpora.net/ice/">International Corpus of English</a>, <a href="https://www.corpusdata.org/">BYU Corpora</a>, etc.), require authorization/ registration (<a href="https://archive.mpi.nl/tla/">The Language Archive</a>, <a href="https://www.webcorpora.org/">COW Corpora</a>, etc.), and/ or are only accessible via resource search interfaces (<a href="https://cesa.arizona.edu/">Corpus of Spanish in Southern Arizona</a>, <a href="http://cedel2.learnercorpora.com/">Corpus Escrito del Español como L2 (CEDEL2)</a>, etc.).</p>
<p>Let’s work with the CEDEL2 corpus <span class="citation">(<a href="references.html#ref-Lozano2009" role="doc-biblioref">Lozano, 2009</a>)</span> which provides a search interface and open access to the data through the search interface. The homepage can be seen in Figure <a href="acquire-data.html#fig:ad-show-page-cedel2-1">5.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-show-page-cedel2-1"></span>
<img src="images/06-acquire-data/ad-cedel2-site.png" alt="CEDEL2 Corpus homepage" width="90%"><p class="caption">
Figure 5.1: CEDEL2 Corpus homepage
</p>
</div>
<p>Following the search/ download link you can find a search interface that allows the user to select the sub-corpus of interest. I’ve selected the subcorpus “Learners of L2 Spanish” and specified the L1 as English.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-show-page-cedel2-2"></span>
<img src="images/06-acquire-data/ad-cedel2-search-download.png" alt="Search and download interface for the CEDEL2 Corpus" width="90%"><p class="caption">
Figure 5.2: Search and download interface for the CEDEL2 Corpus
</p>
</div>
<p>The ‘Download’ link now appears for this search criteria. Following this link will provide the user a form to fill out. This particular resource allows for access to different formats to download (Texts only, Texts with metadata, CSV (Excel), CSV (Others)). I will select the ‘CSV (Others)’ option so that the data is structured for easier processing downstream when we work to curate the data in our next processing step. Then I will choose to save the CSV in the <code>data/original/</code> directory of my project and create a sub-directory called <code>cedel2/</code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="acquire-data.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb11-2"><a href="acquire-data.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb11-3"><a href="acquire-data.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb11-4"><a href="acquire-data.html#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> cedel2</span>
<span id="cb11-5"><a href="acquire-data.html#cb11-5" aria-hidden="true" tabindex="-1"></a>       <span class="ex">└──</span> texts.csv</span></code></pre></div>
<p>Other resources will inevitably include unique processes to obtaining the data, but in the end the data should be archived in the research structure in the <code>data/original/</code> directory and be treated as ‘read-only.’</p>
</div>
<div id="programmatic" class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> Programmatic<a class="anchor" aria-label="anchor" href="#programmatic"><i class="fas fa-link"></i></a>
</h3>
<p>There are many resources that provide corpus data is directly accessible for which programmatic approaches can be applied. Let’s take a look at how this works starting with the a sample from the Switchboard Corpus, a corpus of 2,400 telephone conversations by 543 speakers. First we navigate to the site with a browser and download the file that we are looking for. In this case I found the Switchboard Corpus on the <a href="http://www.nltk.org/nltk_data/">NLTK data repository site</a>. More often than not this file will be some type of compressed archive file with an extension such as <code>.zip</code> or <code>.tz</code>, which is the case here. Archive files make downloading large single files or multiple files easy by grouping files and directories into one file. In R we can used the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function from the base R library<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Remember base R packages are installed by default with R and are loaded and accessible by default in each R session.&lt;/p&gt;"><sup>14</sup></a>. There are a number of <strong>arguments</strong> that a function may require or provide optionally. The <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function minimally requires two: <code>url</code> and <code>destfile</code>. That is the file to download and the location where it is to be saved to disk.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Download .zip file and write to disk</span>
<span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip"</span>,
    destfile <span class="op">=</span> <span class="st">"../data/original/switchboard.zip"</span><span class="op">)</span></code></pre></div>
<p>As we can see looking at the directory structure for <code>data/</code> the <code>switchboard.zip</code> file has been downloaded.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><a href="acquire-data.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb13-2"><a href="acquire-data.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb13-3"><a href="acquire-data.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb13-4"><a href="acquire-data.html#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> switchboard.zip</span></code></pre></div>
<p>Once an archive file is downloaded, however, the file needs to be ‘decompressed’ to reveal the file structure. To decompress this file we use the <code><a href="https://rdrr.io/r/utils/unzip.html">unzip()</a></code> function with the arguments <code>zipfile</code> pointing to the <code>.zip</code> file and <code>exdir</code> specifying the directory where we want the files to be extracted to.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Decompress .zip file and extract to our target directory</span>
<span class="fu"><a href="https://rdrr.io/r/utils/unzip.html">unzip</a></span><span class="op">(</span>zipfile <span class="op">=</span> <span class="st">"../data/original/switchboard.zip"</span>, exdir <span class="op">=</span> <span class="st">"../data/original/"</span><span class="op">)</span></code></pre></div>
<p>The directory structure of <code>data/</code> now should look like this:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="acquire-data.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb15-2"><a href="acquire-data.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb15-3"><a href="acquire-data.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb15-4"><a href="acquire-data.html#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> switchboard</span>
<span id="cb15-5"><a href="acquire-data.html#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── README</span>
<span id="cb15-6"><a href="acquire-data.html#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── discourse</span>
<span id="cb15-7"><a href="acquire-data.html#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── disfluency</span>
<span id="cb15-8"><a href="acquire-data.html#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── tagged</span>
<span id="cb15-9"><a href="acquire-data.html#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── timed-transcript</span>
<span id="cb15-10"><a href="acquire-data.html#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcript</span>
<span id="cb15-11"><a href="acquire-data.html#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> switchboard.zip</span></code></pre></div>
<p>At this point we have acquired the data programmatically and with this code as part of our workflow anyone could run this code and reproduce the same results. The code as it is, however, is not ideally efficient. Firstly the <code>switchboard.zip</code> file is not strictly needed after we decompress it and it occupies disk space if we keep it. And second, each time we run this code the file will be downloaded from the remote serve leading to unnecessary data transfer and server traffic. Let’s tackle each of these issues in turn.</p>
<p>To avoid writing the <code>switchboard.zip</code> file to disk (long-term) we can use the <code><a href="https://rdrr.io/r/base/tempfile.html">tempfile()</a></code> function to open a temporary holding space for the file. This space can then be used to store the file, unzip it, and then the temporary file will be destroyed. We assign the temporary space to an R object we will name <code>temp</code> with the <code><a href="https://rdrr.io/r/base/tempfile.html">tempfile()</a></code> function. This object can now be used as the value of the argument <code>destfile</code> in the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function. Let’s also assign the web address to another object <code>url</code> which we will use as the value of the <code>url</code> argument.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Create a temporary file space for our .zip file</span>
<span class="va">temp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempfile</a></span><span class="op">(</span><span class="op">)</span>
<span class="co"># Assign our web address to `url`</span>
<span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip"</span>
<span class="co"># Download .zip file and write to disk</span>
<span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="va">url</span>, <span class="va">temp</span><span class="op">)</span></code></pre></div>
<div class="rmdtip">
<p>
In the previous code I’ve used the values stored in the objects <code>url</code> and <code>temp</code> in the <code><a href="https://rdrr.io/r/utils/download.file.html">download.file()</a></code> function without specifying the argument names –only providing the names of the objects. R will assume that values of a function map to the ordering of the arguments. If your values do not map to ordering of the arguments you are required to specify the argument name and the value. To view the ordering of objects hit <code>TAB</code> after entering the function name or consult the function documentation by prefixing the function name with <code>?</code> and hitting <code>ENTER</code>.
</p>
</div>
<p>At this point our downloaded file is stored temporarily on disk and can be accessed and decompressed to our target directory using <code>temp</code> as the value for the argument <code>zipfile</code> from the <code><a href="https://rdrr.io/r/utils/unzip.html">unzip()</a></code> function. I’ve assigned our target directory path to <code>target_dir</code> and used it as the value for the argument <code>exdir</code> to prepare us for the next tweak on our approach.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Assign our target directory to `target_dir`</span>
<span class="va">target_dir</span> <span class="op">&lt;-</span> <span class="st">"../data/original/"</span>
<span class="co"># Decompress .zip file and extract to our target directory</span>
<span class="fu"><a href="https://rdrr.io/r/utils/unzip.html">unzip</a></span><span class="op">(</span>zipfile <span class="op">=</span> <span class="va">temp</span>, exdir <span class="op">=</span> <span class="va">target_dir</span><span class="op">)</span></code></pre></div>
<p>Our directory structure now looks like this:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb18-1"><a href="acquire-data.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb18-2"><a href="acquire-data.html#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb18-3"><a href="acquire-data.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb18-4"><a href="acquire-data.html#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> switchboard</span>
<span id="cb18-5"><a href="acquire-data.html#cb18-5" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> README</span>
<span id="cb18-6"><a href="acquire-data.html#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> discourse</span>
<span id="cb18-7"><a href="acquire-data.html#cb18-7" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> disfluency</span>
<span id="cb18-8"><a href="acquire-data.html#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> tagged</span>
<span id="cb18-9"><a href="acquire-data.html#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> timed-transcript</span>
<span id="cb18-10"><a href="acquire-data.html#cb18-10" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> transcript</span></code></pre></div>
<p>The second issue I raised concerns the fact that running this code as part of our project will repeat the download each time. Since we would like to be good citizens and avoid unnecessary traffic on the web it would be nice if our code checked to see if we already have the data on disk and if it exists, then skip the download, if not then download it.</p>
<p>To achieve this we need to introduce two new functions <code>if()</code> and <code><a href="https://rdrr.io/r/base/files2.html">dir.exists()</a></code>. <code><a href="https://rdrr.io/r/base/files2.html">dir.exists()</a></code> takes a path to a directory as an argument and returns the logical value, <code>TRUE</code>, if that directory exists, and <code>FALSE</code> if it does not. <code>if()</code> evaluates logical statements and processes subsequent code based on the logical value it is passed as an argument. Let’s look at a toy example.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">num</span> <span class="op">&lt;-</span> <span class="fl">1</span>
<span class="kw">if</span> <span class="op">(</span><span class="va">num</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is 1"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is not 1"</span><span class="op">)</span>
<span class="op">}</span>
<span class="co">#&gt; 1 is 1</span></code></pre></div>
<p>I assigned <code>num</code> to the value <code>1</code> and created a logical evaluation <code>num ==</code> whose result is passed as the argument to <code>if()</code>. If the statement returns <code>TRUE</code> then the code withing the first set of curly braces <code>{...}</code> is run. If <code>num == 1</code> is false, like in the code below, the code withing the braces following the <code>else</code> will be run.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">num</span> <span class="op">&lt;-</span> <span class="fl">2</span>
<span class="kw">if</span> <span class="op">(</span><span class="va">num</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is 1"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is not 1"</span><span class="op">)</span>
<span class="op">}</span>
<span class="co">#&gt; 2 is not 1</span></code></pre></div>
<p>The function <code>if()</code> is one of various functions that are called <strong>control statements</strong>. Theses functions provide a lot of power to make dynamic choices as code is run.</p>
<p>Before we get back to our key objective to avoid downloading resources that we already have on disk, let me introduce another strategy to making code more powerful and ultimately more efficient and as well as more legible –the <strong>custom function</strong>. Custom functions are functions that the user writes to create a set of procedures that can be run in similar contexts. I’ve created a custom function named <code>eval_num()</code> below.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">eval_num</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">num</span><span class="op">)</span> <span class="op">{</span>
    <span class="kw">if</span> <span class="op">(</span><span class="va">num</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is 1"</span><span class="op">)</span>
    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="va">num</span>, <span class="st">"is not 1"</span><span class="op">)</span>
    <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Let’s take a closer look at what’s going on here. The function <code>function()</code> creates a function in which the user decides what arguments are necessary for the code to perform its task. In this case the only necessary argument is the object to store a numeric value to be evaluated. I’ve called it <code>num</code> because it reflects the name of the object in our toy example, but there is nothing special about this name. It’s only important that the object names be consistently used. I’ve included our previous code (except for the hard-coded assignment of <code>num</code>) inside the curly braces and assigned the entire code chunk to <code>eval_num</code>.</p>
<p>We can now use the function <code>eval_num()</code> to perform the task of evaluating whether a value of <code>num</code> is or is not equal to <code>1</code>.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">eval_num</span><span class="op">(</span>num <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt; 1 is 1</span>
<span class="fu">eval_num</span><span class="op">(</span>num <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="co">#&gt; 2 is not 1</span>
<span class="fu">eval_num</span><span class="op">(</span>num <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt; 3 is not 1</span></code></pre></div>
<p>I’ve put these coding strategies together with our previous code in a custom function I named <code>get_zip_data()</code>. There is a lot going on here. Take a look first and see if you can follow the logic involved given what you now know.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">get_zip_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">url</span>, <span class="va">target_dir</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Function: to download and decompress a .zip file to a target directory</span>

    <span class="co"># Check to see if the data already exists if data does not exist, download/</span>
    <span class="co"># decompress</span>
    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.exists</a></span><span class="op">(</span><span class="va">target_dir</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Creating target data directory \n"</span><span class="op">)</span>  <span class="co"># print status message</span>
        <span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">target_dir</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span>, showWarnings <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>  <span class="co"># create target data directory</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Downloading data... \n"</span><span class="op">)</span>  <span class="co"># print status message</span>
        <span class="va">temp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html">tempfile</a></span><span class="op">(</span><span class="op">)</span>  <span class="co"># create a temporary space for the file to be written to</span>
        <span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span>url <span class="op">=</span> <span class="va">url</span>, destfile <span class="op">=</span> <span class="va">temp</span><span class="op">)</span>  <span class="co"># download the data to the temp file</span>
        <span class="fu"><a href="https://rdrr.io/r/utils/unzip.html">unzip</a></span><span class="op">(</span>zipfile <span class="op">=</span> <span class="va">temp</span>, exdir <span class="op">=</span> <span class="va">target_dir</span>, junkpaths <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># decompress the temp file in the target directory</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data downloaded! \n"</span><span class="op">)</span>  <span class="co"># print status message</span>
    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
        <span class="co"># if data exists, don't download it again</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data already exists \n"</span><span class="op">)</span>  <span class="co"># print status message</span>
    <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>OK. You should have recognized the general steps in this function: the argument <code>url</code> and <code>target_dir</code> specify where to get the data and where to write the decompressed files, the <code>if()</code> statement evaluates whether the data already exists, if not (<code>!dir.exists(target_dir)</code>) then the data is downloaded and decompressed, if it does exist (<code>else</code>) then it is not downloaded.</p>
<div class="rmdtip">
<p>
The prefixed <code>!</code> in the logical expression <code>dir.exists(target_dir)</code> returns the opposite logical value. This is needed in this case so when the target directory exists, the expression will return <code>FALSE</code>, not <code>TRUE</code>, and therefore not proceed in downloading the resource.
</p>
</div>
<p>There are a couple key tweaks I’ve added that provide some additional functionality. For one I’ve included the function <code><a href="https://rdrr.io/r/base/files2.html">dir.create()</a></code> to create the target directory where the data will be written. I’ve also added an additional argument to the <code><a href="https://rdrr.io/r/utils/unzip.html">unzip()</a></code> function, <code>junkpaths = TRUE</code>. Together these additions allow the user to create an arbitrary directory path where the files, and only the files, will be extracted to on our disk. This will discard the containing directory of the <code>.zip</code> file which can be helpful when we want to add multiple <code>.zip</code> files to the same target directory.</p>
<p>A practical scenario where this applies is when we want to download data from a corpus that is contained in multiple <code>.zip</code> files but still maintain these files in a single primary data directory. Take for example the <a href="http://www.linguistics.ucsb.edu/research/santa-barbara-corpus">Santa Barbara Corpus</a>. This corpus resource includes a series of interviews in which there is one <code>.zip</code> file, <code>SBCorpus.zip</code> which contains the <a href="http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/SBCorpus.zip">transcribed interviews</a> and another <code>.zip</code> file, <code>metadata.zip</code> which organizes the <a href="http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/metadata.zip">meta-data</a> associated with each speaker. Applying our initial strategy to download and decompress the data will lead to the following directory structure:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb24-1"><a href="acquire-data.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb24-2"><a href="acquire-data.html#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb24-3"><a href="acquire-data.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb24-4"><a href="acquire-data.html#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> SBCorpus</span>
<span id="cb24-5"><a href="acquire-data.html#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── TRN</span>
<span id="cb24-6"><a href="acquire-data.html#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── __MACOSX</span>
<span id="cb24-7"><a href="acquire-data.html#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span>     └── TRN</span>
<span id="cb24-8"><a href="acquire-data.html#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> metadata</span>
<span id="cb24-9"><a href="acquire-data.html#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> __MACOSX</span></code></pre></div>
<p>By applying our new custom function <code>get_zip_data()</code> to the transcriptions and then the meta-data we can better organize the data.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Download corpus transcriptions</span>
<span class="fu">get_zip_data</span><span class="op">(</span>url <span class="op">=</span> <span class="st">"http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/SBCorpus.zip"</span>,
    target_dir <span class="op">=</span> <span class="st">"../data/original/sbc/transcriptions/"</span><span class="op">)</span>

<span class="co"># Download corpus meta-data</span>
<span class="fu">get_zip_data</span><span class="op">(</span>url <span class="op">=</span> <span class="st">"http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/metadata.zip"</span>,
    target_dir <span class="op">=</span> <span class="st">"../data/original/sbc/meta-data/"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb26-1"><a href="acquire-data.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb26-2"><a href="acquire-data.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb26-3"><a href="acquire-data.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb26-4"><a href="acquire-data.html#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> sbc</span>
<span id="cb26-5"><a href="acquire-data.html#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> meta-data</span>
<span id="cb26-6"><a href="acquire-data.html#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> transcriptions</span></code></pre></div>
<p>If we add data from other sources we can keep them logical separate and allow our data collection to scale without creating unnecessary complexity. Let’s add the Switchboard Corpus sample using our <code>get_zip_data()</code> function to see this in action.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Download corpus</span>
<span class="fu">get_zip_data</span><span class="op">(</span>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip"</span>,
    target_dir <span class="op">=</span> <span class="st">"../data/original/scs/"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb28-1"><a href="acquire-data.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb28-2"><a href="acquire-data.html#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb28-3"><a href="acquire-data.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb28-4"><a href="acquire-data.html#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc</span>
<span id="cb28-5"><a href="acquire-data.html#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── meta-data</span>
<span id="cb28-6"><a href="acquire-data.html#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcriptions</span>
<span id="cb28-7"><a href="acquire-data.html#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> scs</span>
<span id="cb28-8"><a href="acquire-data.html#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> README</span>
<span id="cb28-9"><a href="acquire-data.html#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> discourse</span>
<span id="cb28-10"><a href="acquire-data.html#cb28-10" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> disfluency</span>
<span id="cb28-11"><a href="acquire-data.html#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> tagged</span>
<span id="cb28-12"><a href="acquire-data.html#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> timed-transcript</span>
<span id="cb28-13"><a href="acquire-data.html#cb28-13" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> transcript</span></code></pre></div>
<p>At this point we have what we need to continue to the next step in our data analysis project. But before we go, we should do some housekeeping to document and organize this process to make our work reproducible. We will take advantage of the <code>project-template</code> directory structure, seen below.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb29-1"><a href="acquire-data.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> README.md</span>
<span id="cb29-2"><a href="acquire-data.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> _pipeline.R</span>
<span id="cb29-3"><a href="acquire-data.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> analysis</span>
<span id="cb29-4"><a href="acquire-data.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── 1_acquire_data.Rmd</span>
<span id="cb29-5"><a href="acquire-data.html#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── 2_curate_dataset.Rmd</span>
<span id="cb29-6"><a href="acquire-data.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── 3_transform_dataset.Rmd</span>
<span id="cb29-7"><a href="acquire-data.html#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── 4_analyze_dataset.Rmd</span>
<span id="cb29-8"><a href="acquire-data.html#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── 5_generate_article.Rmd</span>
<span id="cb29-9"><a href="acquire-data.html#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── _session-info.Rmd</span>
<span id="cb29-10"><a href="acquire-data.html#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── _site.yml</span>
<span id="cb29-11"><a href="acquire-data.html#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── index.Rmd</span>
<span id="cb29-12"><a href="acquire-data.html#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   └── references.bib</span>
<span id="cb29-13"><a href="acquire-data.html#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> data</span>
<span id="cb29-14"><a href="acquire-data.html#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   ├── derived</span>
<span id="cb29-15"><a href="acquire-data.html#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>   └── original</span>
<span id="cb29-16"><a href="acquire-data.html#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>       ├── sbc</span>
<span id="cb29-17"><a href="acquire-data.html#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="ex">│</span>       └── scs</span>
<span id="cb29-18"><a href="acquire-data.html#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> functions</span>
<span id="cb29-19"><a href="acquire-data.html#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> output</span>
<span id="cb29-20"><a href="acquire-data.html#cb29-20" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> figures</span>
<span id="cb29-21"><a href="acquire-data.html#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> results</span></code></pre></div>
<p>First it is good practice to separate custom functions from our processing scripts. We can create a file in our <code>functions/</code> directory named <code>acquire_functions.R</code> and add our custom function <code>get_zip_data()</code> there.</p>
<div class="rmdtip">
<p>
Note that that the <code>acquire_functions.R</code> file is an R script, not an Rmarkdown document. Therefore code chunks that are used in <code>.Rmd</code> files are not used, only the R code itself.
</p>
</div>
<p>We then use the <code><a href="https://rdrr.io/r/base/source.html">source()</a></code> function to read that function into our current script to make it available to use as needed. It is good practice to source your functions in the SETUP section of your script.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Load custom functions for this project</span>
<span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span>file <span class="op">=</span> <span class="st">"../functions/acquire_functions.R"</span><span class="op">)</span></code></pre></div>
<p>In this section, to sum up, we’ve covered how to access, download, and organize data contained in .zip files; the most common format for language data found on repositories and individual sites. This included an introduction to a few key R programming concepts and strategies including using functions, writing custom functions, and controlling program flow with control statements. Our approach was to gather data while also keeping in mind the reproducibility of the code. To this end I introduced programming strategies for avoiding unnecessary web traffic (downloads), scalable directory creation, and data documentation.</p>
<div class="rmdnote">
<p>
The custom function <code>get_zip_data()</code> works with <code>.zip</code> files. There are many other compressed file formats (e.g. <code>.gz</code>, <code>.tar</code>, <code>.tgz</code>), however. In the R package <code>tadr</code> that accompanies this coursebook, a modified version of the <code>get_zip_data()</code> function, <code>get_compressed_data()</code>, extends the same logic to deal with a wider range of compressed file formats, including <code>.zip</code> files.
</p>
<p>
Explore this function’s documentation (<code>?tadr::get_compressed_data()</code>) and/ or view the code (<code><a href="https://rdrr.io/pkg/tadr/man/get_compressed_data.html">tadr::get_compressed_data</a></code>) to better understand this function.
</p>
</div>
</div>
</div>
<div id="apis" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> APIs<a class="anchor" aria-label="anchor" href="#apis"><i class="fas fa-link"></i></a>
</h2>
<p>A convenient alternative method for acquiring data in R is through package interfaces to web services. These interfaces are built using R code to make connections with resources on the web through <strong>Application Programming Interfaces</strong> (APIs). Websites such as Project Gutenberg, Twitter, Facebook, and many others provide APIs to allow access to their data under certain conditions, some more limiting for data collection than others. Programmers (like you!) in the R community take up the task of wrapping calls to an API with R code to make accessing that data from R possible. For example, <a href="https://CRAN.R-project.org/package=gutenbergr">gutenbergr</a> provides access to Project Gutenberg, <a href="https://CRAN.R-project.org/package=rtweet">rtweet</a> to Twitter, and <a href="https://CRAN.R-project.org/package=Rfacebook">Rfacebook</a> to Facebook.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;See Section &lt;a href="understanding-data.html#sources"&gt;2.1.3.2&lt;/a&gt; for a list of some other API packages.&lt;/p&gt;'><sup>15</sup></a></p>
<!-- RESOURCES:
- [rwhatsapp](https://github.com/JBGruber/rwhatsapp) work with personal chat history 
- 
-->
<div id="open-access" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Open access<a class="anchor" aria-label="anchor" href="#open-access"><i class="fas fa-link"></i></a>
</h3>
<p>Using R package interfaces, however, often requires some more knowledge about R objects and functions. Let’s take a look at how to access data from Project Gutenberg through the <code>gutenbergr</code> package. Along the way we will touch upon various functions and concepts that are key to working with the R data types vectors and data frames including filtering and writing tabular data to disk in plain-text format.</p>
<p>To get started let’s install and/ or load the <code>gutenbergr</code> package. If a package is not part of the R base library, we cannot assume that the user will have the package in their library. The standard approach for installing and then loading a package is by using the <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code> function and then calling <code><a href="https://rdrr.io/r/base/library.html">library()</a></code>.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"gutenbergr"</span><span class="op">)</span>  <span class="co"># install `gutenbergr` package</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/gutenbergr/">gutenbergr</a></span><span class="op">)</span>  <span class="co"># load the `gutenbergr` package</span></code></pre></div>
<p>This approach works just fine, but luck has it that there is an R package for installing and loading packages! The <a href="https://CRAN.R-project.org/package=pacman">pacman</a> package includes a set of functions for managing packages. A very useful one is <code>p_load()</code> which will look for a package on a system, load it if it is found, and install and then load it if it is not found. This helps potentially avoid using unnecessary bandwidth to install packages that may already exist on a user’s system. But, to use <code>pacman</code> we need to include the code to install and load it with the functions <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code> and <code><a href="https://rdrr.io/r/base/library.html">library()</a></code>. I’ve included some code that will mimic the behavior of <code>p_load()</code> for installing <code>pacman</code> itself, but as you can see it is not elegant, luckily it’s only used once as we add it to the SETUP section of our master file, <code>_pipeline.R</code>.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Load `pacman`. If not installed, install then load.</span>
<span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="st"><a href="https://github.com/trinker/pacman">"pacman"</a></span>, character.only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span>
    <span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/trinker/pacman">"pacman"</a></span>, character.only <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Now that we have <code>pacman</code> installed and loaded into our R session, let’s use the <code>p_load()</code> function to make sure to install/ load the two packages we will need for the upcoming tasks. If you are following along with the <code>project_template</code>, add this code within the SETUP section of the <code>1_acquire_data.Rmd</code> file.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Script-specific options or packages</span>
<span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">gutenbergr</span><span class="op">)</span></code></pre></div>
<div class="rmdwarning">
<p>
Note that the arguments <code>tidyverse</code> and <code>gutenbergr</code> are comma-separated but not quoted when using <code>p_load()</code>. When using <code><a href="https://rdrr.io/r/utils/install.packages.html">install.packages()</a></code> to install, package names need to be quoted (character strings). <code><a href="https://rdrr.io/r/base/library.html">library()</a></code> can take quotes or no quotes, but only one package at a time.
</p>
</div>
<p>Project Gutenberg provides access to thousands of texts in the public domain. The <code>gutenbergr</code> package contains a set of tables, or <strong>data frames</strong> in R speak, that index the meta-data for these texts broken down by text (<code>gutenberg_metadata</code>), author (<code>gutenberg_authors</code>), and subject (<code>gutenberg_subjects</code>). I’ll use the <code><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse()</a></code> function loaded in the <a href="https://CRAN.R-project.org/package=tidyverse">tidyverse</a> package<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;code&gt;tidyverse&lt;/code&gt; is not a typical package. It is a set of packages: &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;tidyr&lt;/code&gt;, &lt;code&gt;readr&lt;/code&gt;, &lt;code&gt;purrr&lt;/code&gt;, and &lt;code&gt;tibble&lt;/code&gt;. These packages are all installed/ loaded with &lt;code&gt;tidyverse&lt;/code&gt; and form the backbone for the type of work you will typically do in most analyses.&lt;/p&gt;"><sup>16</sup></a> to summarize the structure of these data frames.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">glimpse</span><span class="op">(</span><span class="va">gutenberg_metadata</span><span class="op">)</span>  <span class="co"># summarize text meta-data</span>
<span class="co">#&gt; Rows: 51,997</span>
<span class="co">#&gt; Columns: 8</span>
<span class="co">#&gt; $ gutenberg_id        &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …</span>
<span class="co">#&gt; $ title               &lt;chr&gt; NA, "The Declaration of Independence of the United…</span>
<span class="co">#&gt; $ author              &lt;chr&gt; NA, "Jefferson, Thomas", "United States", "Kennedy…</span>
<span class="co">#&gt; $ gutenberg_author_id &lt;int&gt; NA, 1638, 1, 1666, 3, 1, 4, NA, 3, 3, NA, 7, 7, 7,…</span>
<span class="co">#&gt; $ language            &lt;chr&gt; "en", "en", "en", "en", "en", "en", "en", "en", "e…</span>
<span class="co">#&gt; $ gutenberg_bookshelf &lt;chr&gt; NA, "United States Law/American Revolutionary War/…</span>
<span class="co">#&gt; $ rights              &lt;chr&gt; "Public domain in the USA.", "Public domain in the…</span>
<span class="co">#&gt; $ has_text            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">gutenberg_authors</span><span class="op">)</span>  <span class="co"># summarize authors meta-data</span>
<span class="co">#&gt; Rows: 16,236</span>
<span class="co">#&gt; Columns: 7</span>
<span class="co">#&gt; $ gutenberg_author_id &lt;int&gt; 1, 3, 4, 5, 7, 8, 9, 10, 12, 14, 16, 17, 18, 20, 2…</span>
<span class="co">#&gt; $ author              &lt;chr&gt; "United States", "Lincoln, Abraham", "Henry, Patri…</span>
<span class="co">#&gt; $ alias               &lt;chr&gt; NA, NA, NA, NA, "Dodgson, Charles Lutwidge", NA, "…</span>
<span class="co">#&gt; $ birthdate           &lt;int&gt; NA, 1809, 1736, NA, 1832, NA, 1819, 1860, 1805, 17…</span>
<span class="co">#&gt; $ deathdate           &lt;int&gt; NA, 1865, 1799, NA, 1898, NA, 1891, 1937, 1844, 18…</span>
<span class="co">#&gt; $ wikipedia           &lt;chr&gt; NA, "http://en.wikipedia.org/wiki/Abraham_Lincoln"…</span>
<span class="co">#&gt; $ aliases             &lt;chr&gt; NA, "United States President (1861-1865)/Lincoln, …</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">gutenberg_subjects</span><span class="op">)</span>  <span class="co"># summarize subjects meta-data</span>
<span class="co">#&gt; Rows: 140,173</span>
<span class="co">#&gt; Columns: 3</span>
<span class="co">#&gt; $ gutenberg_id &lt;int&gt; 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, …</span>
<span class="co">#&gt; $ subject_type &lt;chr&gt; "lcc", "lcsh", "lcsh", "lcc", "lcc", "lcsh", "lcsh", "lcc…</span>
<span class="co">#&gt; $ subject      &lt;chr&gt; "E201", "United States. Declaration of Independence", "Un…</span></code></pre></div>

<div class="rmdtip">
<p>The <code>gutenberg_metadata</code>, <code>gutenberg_authors</code>, and <code>gutenberg_subjects</code> are periodically updated. To check to see when each data frame was last updated run:</p>
<p><code>attr(gutenberg_metadata, "date_updated")</code></p>
</div>
<p>To download the text itself we use the <code><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download()</a></code> function which takes one required argument, <code>gutenberg_id</code>. The <code><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download()</a></code> function is what is known as ‘vectorized,’ that is, it can take a single value or multiple values for the argument <code>gutenberg_id</code>. Vectorization refers to the process of applying a function to each of the elements stored in a <strong>vector</strong> –a primary object type in R. A vector is a grouping of values of one of various types including character (<code>chr</code>), integer (<code>int</code>), double (<code>dbl</code>), and logical (<code>lgl</code>) and a data frame is a grouping of vectors. The <code><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download()</a></code> function takes an integer vector which can be manually added or selected from the <code>gutenberg_metadata</code> or <code>gutenberg_subjects</code> data frames using the <code>$</code> operator (e.g. <code>gutenberg_metadata$gutenberg_id</code>).</p>
<p>Let’s first add them manually here as a toy example by generating a vector of integers from 1 to 5 assigned to the variable name <code>ids</code>.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ids</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span>  <span class="co"># integer vector of values 1 to 5</span>
<span class="va">ids</span>
<span class="co">#&gt; [1] 1 2 3 4 5</span></code></pre></div>
<p>To download the works from Project Gutenberg corresponding to the <code>gutenberg_id</code>s 1 to 5, we pass the <code>ids</code> object to the <code><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download()</a></code> function.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">works_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download</a></span><span class="op">(</span>gutenberg_id <span class="op">=</span> <span class="va">ids</span><span class="op">)</span>  <span class="co"># download works with `gutenberg_id` 1-5</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">works_sample</span><span class="op">)</span>  <span class="co"># summarize `works` dataset</span>
<span class="co">#&gt; Rows: 2,959</span>
<span class="co">#&gt; Columns: 2</span>
<span class="co">#&gt; $ gutenberg_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</span>
<span class="co">#&gt; $ text         &lt;chr&gt; "December, 1971  [Etext #1]", "", "", "The Project Gutenb…</span></code></pre></div>
<p>Two attributes are returned: <code>gutenberg_id</code> and <code>text</code>. The <code>text</code> column contains values for each line of text (delimited by a carriage return) for each of the 5 works we downloaded. There are many more attributes available from the Project Gutenberg API that can be accessed by passing a character vector of the attribute names to the argument <code>meta_fields</code>. The column names of the <code>gutenberg_metadata</code> data frame contains the available attributes.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">gutenberg_metadata</span><span class="op">)</span>  <span class="co"># print the column names of the `gutenberg_metadata` data frame</span>
<span class="co">#&gt; [1] "gutenberg_id"        "title"               "author"             </span>
<span class="co">#&gt; [4] "gutenberg_author_id" "language"            "gutenberg_bookshelf"</span>
<span class="co">#&gt; [7] "rights"              "has_text"</span></code></pre></div>
<p>Let’s augment our previous download with the title and author of each of the works. To create a character vector we use the <code><a href="https://rdrr.io/r/base/c.html">c()</a></code> function, then, quote and delimit the individual elements of the vector with a comma.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># download works with `gutenberg_id` 1-5 including `title` and `author` as</span>
<span class="co"># attributes</span>
<span class="va">works_sample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download</a></span><span class="op">(</span>gutenberg_id <span class="op">=</span> <span class="va">ids</span>, meta_fields <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"title"</span>, <span class="st">"author"</span><span class="op">)</span><span class="op">)</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">works_sample</span><span class="op">)</span>  <span class="co"># summarize dataset</span>
<span class="co">#&gt; Rows: 2,959</span>
<span class="co">#&gt; Columns: 4</span>
<span class="co">#&gt; $ gutenberg_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …</span>
<span class="co">#&gt; $ text         &lt;chr&gt; "December, 1971  [Etext #1]", "", "", "The Project Gutenb…</span>
<span class="co">#&gt; $ title        &lt;chr&gt; "The Declaration of Independence of the United States of …</span>
<span class="co">#&gt; $ author       &lt;chr&gt; "Jefferson, Thomas", "Jefferson, Thomas", "Jefferson, Tho…</span></code></pre></div>
<p>Now, in a more practical scenario we would like to select the values of <code>gutenberg_id</code> by some principled query such as works from a specific author, language, or subject. To do this we first query either the <code>gutenberg_metadata</code> data frame or the <code>gutenberg_subjects</code> data frame. Let’s say we want to download a random sample of 10 works from English Literature (Library of Congress Classification, “PR”). Using the <code><a href="https://dplyr.tidyverse.org/reference/filter.html">dplyr::filter()</a></code> function (<code>dplyr</code> is part of the <code>tidyverse</code> package set) we first extract all the Gutenberg ids from <code>gutenberg_subjects</code> where <code>subject_type == "lcc"</code> and <code>subject == "PR"</code> assigning the result to <code>ids</code>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;See &lt;a href="https://www.loc.gov/catdir/cpso/lcco/"&gt;Library of Congress Classification&lt;/a&gt; documentation for a complete list of subject codes.&lt;/p&gt;'><sup>17</sup></a></p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># filter for only English literature</span>
<span class="va">ids</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">gutenberg_subjects</span>, <span class="va">subject_type</span> <span class="op">==</span> <span class="st">"lcc"</span>, <span class="va">subject</span> <span class="op">==</span> <span class="st">"PR"</span><span class="op">)</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">ids</span><span class="op">)</span>
<span class="co">#&gt; Rows: 7,100</span>
<span class="co">#&gt; Columns: 3</span>
<span class="co">#&gt; $ gutenberg_id &lt;int&gt; 11, 12, 13, 16, 20, 26, 27, 35, 36, 42, 43, 46, 58, 60, 8…</span>
<span class="co">#&gt; $ subject_type &lt;chr&gt; "lcc", "lcc", "lcc", "lcc", "lcc", "lcc", "lcc", "lcc", "…</span>
<span class="co">#&gt; $ subject      &lt;chr&gt; "PR", "PR", "PR", "PR", "PR", "PR", "PR", "PR", "PR", "PR…</span></code></pre></div>
<div class="rmdwarning">
<p>
The operators <code>=</code> and <code>==</code> are not equivalents. <code>==</code> is used for logical evaluation and <code>=</code> is an alternate notation for variable assignment (<code>&lt;-</code>).
</p>
</div>
<p>The <code>gutenberg_subjects</code> data frame does not contain information as to whether a <code>gutenberg_id</code> is associated with a plain-text version. To limit our query to only those English Literature works with text, we filter the <code>gutenberg_metadata</code> data frame by the ids we have selected in <code>ids</code> and the attribute <code>has_text</code> in the <code>gutenberg_metadata</code> data frame.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Filter for only those works that have text</span>
<span class="va">ids_has_text</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">gutenberg_metadata</span>, 
         <span class="va">gutenberg_id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">ids</span><span class="op">$</span><span class="va">gutenberg_id</span>, 
         <span class="va">has_text</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">ids_has_text</span><span class="op">)</span>
<span class="co">#&gt; Rows: 6,724</span>
<span class="co">#&gt; Columns: 8</span>
<span class="co">#&gt; $ gutenberg_id        &lt;int&gt; 11, 12, 13, 16, 20, 26, 27, 35, 36, 42, 43, 46, 58…</span>
<span class="co">#&gt; $ title               &lt;chr&gt; "Alice's Adventures in Wonderland", "Through the L…</span>
<span class="co">#&gt; $ author              &lt;chr&gt; "Carroll, Lewis", "Carroll, Lewis", "Carroll, Lewi…</span>
<span class="co">#&gt; $ gutenberg_author_id &lt;int&gt; 7, 7, 7, 10, 17, 17, 23, 30, 30, 35, 35, 37, 17, 4…</span>
<span class="co">#&gt; $ language            &lt;chr&gt; "en", "en", "en", "en", "en", "en", "en", "en", "e…</span>
<span class="co">#&gt; $ gutenberg_bookshelf &lt;chr&gt; "Children's Literature", "Children's Literature/Be…</span>
<span class="co">#&gt; $ rights              &lt;chr&gt; "Public domain in the USA.", "Public domain in the…</span>
<span class="co">#&gt; $ has_text            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…</span></code></pre></div>

<div class="rmdtip">
A couple R programming notes on the code phrase <code>gutenberg_id %in% ids$gutenberg_id</code>. First, the <code>$</code> symbol in <code>ids$gutenberg_id</code> is the programmatic way to target a particular column in an R data frame. In this example we select the <code>ids</code> data frame and the column <code>gutenberg_id</code>, which is a integer vector. The <code>gutenberg_id</code> variable that precedes the <code>%in%</code> operator does not need an explicit reference to a data frame because the primary argument of the <code><a href="https://dplyr.tidyverse.org/reference/filter.html">filter()</a></code> function is this data frame (<code>gutenberg_metadata</code>). Second, the <code>%in%</code> operator logically evaluates whether the vector elements in <code>gutenberg_metadata$gutenberg_ids</code> are also found in the vector <code>ids$gutenberg_id</code> returning <code>TRUE</code> and <code>FALSE</code> accordingly. This effectively filters those ids which are not in both vectors.
</div>
<p>As we can see the number of works with text is fewer than the number of works listed, 7100 versus 6724. Now we can safely do our random selection of 10 works, with the function <code><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_sample()</a></code> and be confident that the ids we select will contain text when we take the next step by downloading the data.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>  <span class="co"># make the sampling reproducible</span>
<span class="va">ids_sample</span> <span class="op">&lt;-</span> <span class="fu">slice_sample</span><span class="op">(</span><span class="va">ids_has_text</span>, n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>  <span class="co"># sample 10 works</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">ids_sample</span><span class="op">)</span>  <span class="co"># summarize the dataset</span>
<span class="co">#&gt; Rows: 10</span>
<span class="co">#&gt; Columns: 8</span>
<span class="co">#&gt; $ gutenberg_id        &lt;int&gt; 10564, 10784, 9316, 1540, 24450, 13821, 7595, 3818…</span>
<span class="co">#&gt; $ title               &lt;chr&gt; "Fairy Gold\nShip's Company, Part 4.", "Sentence D…</span>
<span class="co">#&gt; $ author              &lt;chr&gt; "Jacobs, W. W. (William Wymark)", "Jacobs, W. W. (…</span>
<span class="co">#&gt; $ gutenberg_author_id &lt;int&gt; 1865, 1865, 2364, 65, 999, 2685, 761, 1317, 3564, …</span>
<span class="co">#&gt; $ language            &lt;chr&gt; "en", "en", "en", "en", "en", "en", "en", "en", "e…</span>
<span class="co">#&gt; $ gutenberg_bookshelf &lt;chr&gt; NA, NA, NA, NA, "Adventure", "Fantasy", NA, NA, NA…</span>
<span class="co">#&gt; $ rights              &lt;chr&gt; "Public domain in the USA.", "Public domain in the…</span>
<span class="co">#&gt; $ has_text            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">works_pr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download</a></span><span class="op">(</span>gutenberg_id <span class="op">=</span> <span class="va">ids_sample</span><span class="op">$</span><span class="va">gutenberg_id</span>, meta_fields <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"author"</span>,
    <span class="st">"title"</span><span class="op">)</span><span class="op">)</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">works_pr</span><span class="op">)</span>  <span class="co"># summarize the dataset</span>
<span class="co">#&gt; Rows: 47,515</span>
<span class="co">#&gt; Columns: 4</span>
<span class="co">#&gt; $ gutenberg_id &lt;int&gt; 1540, 1540, 1540, 1540, 1540, 1540, 1540, 1540, 1540, 154…</span>
<span class="co">#&gt; $ text         &lt;chr&gt; "cover ", "", "", "", "THE TEMPEST", "", "", "", "by Will…</span>
<span class="co">#&gt; $ author       &lt;chr&gt; "Shakespeare, William", "Shakespeare, William", "Shakespe…</span>
<span class="co">#&gt; $ title        &lt;chr&gt; "The Tempest", "The Tempest", "The Tempest", "The Tempest…</span></code></pre></div>
<p>At this point we have data and could move on to processing this dataset in preparation for analysis. However, we are aiming for a reproducible workflow and this code does not conform to our principle of modularity: each subsequent step in our analysis will depend on running this code first. Furthermore, running this code as it is creates issues with bandwidth, as in our previous examples from direct downloads. To address modularity we will write the dataset to disk in <strong>plain-text format</strong>. In this way each subsequent step in our analysis can access the dataset locally. To address bandwidth concerns, we will devise a method for checking to see if the dataset is already downloaded and skip the download, if possible, to avoid accessing the Project Gutenberg server unnecessarily.</p>
<p>To write our data frame to disk we will export it into a standard plain-text format for two-dimensional datasets: a CSV file (comma-separated value). The CSV structure for this dataset will look like this:</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">works_pr</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu">format_csv</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; gutenberg_id,text,author,title</span>
<span class="co">#&gt; 1540,cover ,"Shakespeare, William",The Tempest</span>
<span class="co">#&gt; 1540,,"Shakespeare, William",The Tempest</span>
<span class="co">#&gt; 1540,,"Shakespeare, William",The Tempest</span>
<span class="co">#&gt; 1540,,"Shakespeare, William",The Tempest</span>
<span class="co">#&gt; 1540,THE TEMPEST,"Shakespeare, William",The Tempest</span>
<span class="co">#&gt; 1540,,"Shakespeare, William",The Tempest</span></code></pre></div>
<p>The first line contains the names of the columns and subsequent lines the observations. Data points that contain commas themselves (e.g. “Shaw, Bernard”) are quoted to avoid misinterpreting these commas a deliminators in our data. To write this dataset to disk we will use the <code>reader::write_csv()</code> function.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">write_csv</span><span class="op">(</span><span class="va">works_pr</span>, file <span class="op">=</span> <span class="st">"../data/original/gutenberg_works_pr.csv"</span><span class="op">)</span></code></pre></div>
<p>To avoid downloading dataset that already resides on disk, let’s implement a similar strategy to the one used for direct downloads (<code>get_zip_data()</code>). I’ve incorporated the code for sampling and downloading data for a particular subject from Project Gutenberg with a control statement to check if the dataset file already exists into a function I named <code>get_gutenberg_subject()</code>. Take a look at this function below.</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">get_gutenberg_subject</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">subject</span>, <span class="va">target_file</span>, <span class="va">sample_size</span> <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># Function: to download texts from Project Gutenberg with </span>
  <span class="co"># a specific LCC subject and write the data to disk.</span>
  
  <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">gutenbergr</span><span class="op">)</span> <span class="co"># install/load necessary packages</span>
  
  <span class="co"># Check to see if the data already exists</span>
  <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co"># if data does not exist, download and write</span>
    <span class="va">target_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html">dirname</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span> <span class="co"># generate target directory for the .csv file</span>
    <span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">target_dir</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span>, showWarnings <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="co"># create target data directory</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Downloading data... \n"</span><span class="op">)</span> <span class="co"># print status message</span>
    <span class="co"># Select all records with a particular LCC subject</span>
    <span class="va">ids</span> <span class="op">&lt;-</span> 
      <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">gutenberg_subjects</span>, 
             <span class="va">subject_type</span> <span class="op">==</span> <span class="st">"lcc"</span>, <span class="va">subject</span> <span class="op">==</span> <span class="va">subject</span><span class="op">)</span> <span class="co"># select subject</span>
    <span class="co"># Select only those records with plain text available</span>
    <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># make the sampling reproducible</span>
    <span class="va">ids_sample</span> <span class="op">&lt;-</span> 
      <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">gutenberg_metadata</span>, 
             <span class="va">gutenberg_id</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="va">ids</span><span class="op">$</span><span class="va">gutenberg_id</span>, <span class="co"># select ids in both data frames </span>
             <span class="va">has_text</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="co"># select those ids that have text</span>
      <span class="fu">slice_sample</span><span class="op">(</span>n <span class="op">=</span> <span class="va">sample_size</span><span class="op">)</span> <span class="co"># sample N works </span>
    <span class="co"># Download sample with associated `author` and `title` metadata</span>
    <span class="va">works_sample</span> <span class="op">&lt;-</span> 
      <span class="fu"><a href="https://docs.ropensci.org/gutenbergr/reference/gutenberg_download.html">gutenberg_download</a></span><span class="op">(</span>gutenberg_id <span class="op">=</span> <span class="va">ids_sample</span><span class="op">$</span><span class="va">gutenberg_id</span>, 
                         meta_fields <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"author"</span>, <span class="st">"title"</span><span class="op">)</span><span class="op">)</span>
    <span class="co"># Write the dataset to disk in .csv format</span>
    <span class="fu">write_csv</span><span class="op">(</span><span class="va">works_sample</span>, file <span class="op">=</span> <span class="va">target_file</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data downloaded! \n"</span><span class="op">)</span> <span class="co"># print status message</span>
  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span> <span class="co"># if data exists, don't download it again</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data already exists \n"</span><span class="op">)</span> <span class="co"># print status message</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Adding this function to our function script <code>functions/acquire_functions.R</code>, we can now source this function in our <code>analysis/1_acquire_data.Rmd</code> script to download multiple subjects and store them in on disk in their own file.</p>
<p>Let’s download American Literature now (LCC code “PQ”).</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Download Project Gutenberg text for subject 'PQ' (American Literature) and</span>
<span class="co"># then write this dataset to disk in .csv format</span>
<span class="fu">get_gutenberg_subject</span><span class="op">(</span>subject <span class="op">=</span> <span class="st">"PQ"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/gutenberg/works_pq.csv"</span><span class="op">)</span></code></pre></div>
<p>Applying this function to both the English and American Literature datasets, our data directory structure now looks like this:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb47-1"><a href="acquire-data.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data</span></span>
<span id="cb47-2"><a href="acquire-data.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived</span>
<span id="cb47-3"><a href="acquire-data.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original</span>
<span id="cb47-4"><a href="acquire-data.html#cb47-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> gutenberg</span>
<span id="cb47-5"><a href="acquire-data.html#cb47-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── works_pq.csv</span>
<span id="cb47-6"><a href="acquire-data.html#cb47-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── works_pr.csv</span>
<span id="cb47-7"><a href="acquire-data.html#cb47-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc</span>
<span id="cb47-8"><a href="acquire-data.html#cb47-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── meta-data</span>
<span id="cb47-9"><a href="acquire-data.html#cb47-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcriptions</span>
<span id="cb47-10"><a href="acquire-data.html#cb47-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> scs</span>
<span id="cb47-11"><a href="acquire-data.html#cb47-11" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> README</span>
<span id="cb47-12"><a href="acquire-data.html#cb47-12" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> discourse</span>
<span id="cb47-13"><a href="acquire-data.html#cb47-13" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> disfluency</span>
<span id="cb47-14"><a href="acquire-data.html#cb47-14" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> documentation</span>
<span id="cb47-15"><a href="acquire-data.html#cb47-15" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> tagged</span>
<span id="cb47-16"><a href="acquire-data.html#cb47-16" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> timed-transcript</span>
<span id="cb47-17"><a href="acquire-data.html#cb47-17" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> transcript</span></code></pre></div>
</div>
<div id="authentication" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Authentication<a class="anchor" aria-label="anchor" href="#authentication"><i class="fas fa-link"></i></a>
</h3>
<p>Some APIs and the R interfaces that provide access to them require authentication. This may either be through an interactive process that is mediated between R and the web service and/ or by visiting the developer website of the particular API. In either case, there is an extra step that is necessary to make the connect to the API to access the data.</p>
<p>Let’s take a look at the popular micro-blogging platform Twitter. The rtweet package <span class="citation">(<a href="references.html#ref-rtweet-package" role="doc-biblioref">Kearney, 2019</a>)</span> provides access to tweets in various ways. To get started install and/or load the rtweet package.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">rtweet</span><span class="op">)</span>  <span class="co"># install/load rtweet package</span></code></pre></div>
<p>Now before a researcher can access data from Twitter with rtweet, <a href="https://docs.ropensci.org/rtweet/articles/auth.html">an authentication token must be setup and made accessible</a>. After following the steps for setting up an authentication token and saving it, that token can be accessed with the <code>auth_as()</code> function.</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">auth_as</span><span class="op">(</span><span class="va">twitter_auth</span><span class="op">)</span>  <span class="co"># load the saved `twitter_auth` token</span></code></pre></div>
<p>Now that we the R session is authenticated, we can explore a popular method for querying the Twitter API which searchs tweets (<code>search_tweets</code>) posted in the recent past (6-9 days).</p>
<p>Let’s look at a typical query using the <code><a href="https://rdrr.io/pkg/rtweet/man/search_tweets.html">search_tweets()</a></code> function.</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rt_latinx</span> <span class="op">&lt;-</span> 
  <span class="fu">search_tweets</span><span class="op">(</span>q <span class="op">=</span> <span class="st">"latinx"</span>, <span class="co"># query term</span>
                n <span class="op">=</span> <span class="fl">100</span>, <span class="co"># number of tweets desired</span>
                type <span class="op">=</span> <span class="st">"mixed"</span>, <span class="co"># a mix of `recent` and `popular` tweets</span>
                include_rts <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="co"># do not include RTs</span></code></pre></div>
<p>Looking at the arguments in this function, we see I’ve specified the query term to be ‘latinx.’ This is a single word query but if the query included multiple words, the spaces between would be interpreted as the logical <code>AND</code> (only match tweets with all the individual terms). If one would like to include multi-word expressions, the expressions should be enclosed by single quotes (i.e. <code>q = "'spanish speakers' AND latinx"</code>). Another approach would be to include the logical <code>OR</code> (match tweets with either of the terms). Multi-word expressions can be included as in the previous case. Of note, hashtags are acceptable terms, so <code>q = "#latinx"</code> would match tweets with this hashtag.</p>
<p>The number of results has been set at ‘100,’ but this is the default, so I could have left it out. But you can increase the number of desired tweets. There are rate limits which cap the number of tweets you can access in a given 15-minute time period.</p>
<p>Another argument of importance is the <code>type</code> argument. This argument has three possible attributes <code>popular</code>, <code>recent</code>, and <code>mixed</code>. When the <code>popular</code> attribute he Twitter API will tend to return fewer tweets than specified by <code>n</code>. With <code>recent</code> or <code>mixed</code> you will most likely get the <code>n</code> you specified (note that <code>mixed</code> is a mix of <code>popular</code> and <code>recent</code>).</p>
<p>A final argument to note is the <code>include_rts</code> whose attribute is logical. If <code>FALSE</code> no retweets will be included in the results. This is often what a language researcher will want.</p>
<p>Now, once the <code>search_tweets</code> query has been run, there a a large number of variables that are included in the resulting data frame. Here’s an overview of the names of the variables and the vector types for each variable.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:ad-rtweet-variables-table">Table 5.1: </span>Variables and variable types returned from Twitter API via rtweet’s <code><a href="https://rdrr.io/pkg/rtweet/man/search_tweets.html">search_tweets()</a></code> function.</caption>
<tbody>
<tr class="odd">
<td align="left">created_at</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">id</td>
<td align="left">double</td>
</tr>
<tr class="odd">
<td align="left">id_str</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">full_text</td>
<td align="left">character</td>
</tr>
<tr class="odd">
<td align="left">truncated</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">display_text_range</td>
<td align="left">double</td>
</tr>
<tr class="odd">
<td align="left">entities</td>
<td align="left">list</td>
</tr>
<tr class="even">
<td align="left">metadata</td>
<td align="left">list</td>
</tr>
<tr class="odd">
<td align="left">source</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">in_reply_to_status_id</td>
<td align="left">double</td>
</tr>
<tr class="odd">
<td align="left">in_reply_to_status_id_str</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">in_reply_to_user_id</td>
<td align="left">double</td>
</tr>
<tr class="odd">
<td align="left">in_reply_to_user_id_str</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">in_reply_to_screen_name</td>
<td align="left">character</td>
</tr>
<tr class="odd">
<td align="left">geo</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">coordinates</td>
<td align="left">list</td>
</tr>
<tr class="odd">
<td align="left">place</td>
<td align="left">list</td>
</tr>
<tr class="even">
<td align="left">contributors</td>
<td align="left">logical</td>
</tr>
<tr class="odd">
<td align="left">is_quote_status</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">retweet_count</td>
<td align="left">integer</td>
</tr>
<tr class="odd">
<td align="left">favorite_count</td>
<td align="left">integer</td>
</tr>
<tr class="even">
<td align="left">favorited</td>
<td align="left">logical</td>
</tr>
<tr class="odd">
<td align="left">retweeted</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">lang</td>
<td align="left">character</td>
</tr>
<tr class="odd">
<td align="left">possibly_sensitive</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">quoted_status_id</td>
<td align="left">double</td>
</tr>
<tr class="odd">
<td align="left">quoted_status_id_str</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">quoted_status</td>
<td align="left">list</td>
</tr>
<tr class="odd">
<td align="left">text</td>
<td align="left">character</td>
</tr>
<tr class="even">
<td align="left">favorited_by</td>
<td align="left">logical</td>
</tr>
<tr class="odd">
<td align="left">display_text_width</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">retweeted_status</td>
<td align="left">logical</td>
</tr>
<tr class="odd">
<td align="left">quoted_status_permalink</td>
<td align="left">logical</td>
</tr>
<tr class="even">
<td align="left">query</td>
<td align="left">logical</td>
</tr>
<tr class="odd">
<td align="left">possibly_sensitive_appealable</td>
<td align="left">logical</td>
</tr>
</tbody>
</table></div>
<p>The <a href="https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets">Twitter API documentation for the standard Search Tweets call</a>, which is what <code><a href="https://rdrr.io/pkg/rtweet/man/search_tweets.html">search_tweets()</a></code> interfaces with has quite a few variables (35 to be exact). For many purposes it is not necessary to keep all the variables. Furthermore, since we will want to write a plain-text file to disk as part of our project, we will need to either convert or eliminate any of the variables that are marked as type <code>list</code>. The most common variable to convert is the <code>coordinates</code> variable, as it will contain the geolocation codes for those Twitter users’ tweets captured in the query that have geolocation enabled on their device. It is of note, however, that using <code><a href="https://rdrr.io/pkg/rtweet/man/search_tweets.html">search_tweets()</a></code> without specifying that only tweets with geocodes should be captured (<code>geocode =</code>) will tend to return very few, if any, tweets with geolocation information as the majority of Twitter users do not have geolocation enabled.</p>
<p>Let’s assume that we want to keep all the variables that are not of type <code>list</code>. One option is to use <code><a href="https://dplyr.tidyverse.org/reference/select.html">select()</a></code> and name each variable we want to keep. On the other hand we can use a combination of <code><a href="https://dplyr.tidyverse.org/reference/select.html">select()</a></code> and negated <code>!where()</code> to select all the variables that are not lists (<code>is_list</code>). Let’s do the later approach.</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rt_latinx_subset</span> <span class="op">&lt;-</span> 
  <span class="va">rt_latinx</span> <span class="op">%&gt;%</span> <span class="co"># dataset</span>
  <span class="fu">select</span><span class="op">(</span><span class="op">!</span><span class="fu">where</span><span class="op">(</span><span class="va">is_list</span><span class="op">)</span><span class="op">)</span>  <span class="co"># select all variables that are NOT lists</span>

<span class="va">rt_latinx_subset</span> <span class="op">%&gt;%</span> <span class="co"># subsetted dataset</span>
  <span class="fu">glimpse</span><span class="op">(</span><span class="op">)</span> <span class="co"># overview</span>
<span class="co">#&gt; Rows: 100</span>
<span class="co">#&gt; Columns: 30</span>
<span class="co">#&gt; $ created_at                    &lt;chr&gt; "Sun Sep 26 17:38:06 +0000 2021", "Sun S…</span>
<span class="co">#&gt; $ id                            &lt;dbl&gt; 1.44e+18, 1.44e+18, 1.44e+18, 1.44e+18, …</span>
<span class="co">#&gt; $ id_str                        &lt;chr&gt; "1442181701967302659", "1442196629801488…</span>
<span class="co">#&gt; $ full_text                     &lt;chr&gt; "If we call it Latinx Mass they can't ca…</span>
<span class="co">#&gt; $ truncated                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…</span>
<span class="co">#&gt; $ display_text_range            &lt;dbl&gt; 57, 177, 166, 23, 261, 153, 202, 211, 57…</span>
<span class="co">#&gt; $ source                        &lt;chr&gt; "&lt;a href=\"https://mobile.twitter.com\" …</span>
<span class="co">#&gt; $ in_reply_to_status_id         &lt;dbl&gt; NA, NA, NA, 1.44e+18, NA, NA, NA, NA, 1.…</span>
<span class="co">#&gt; $ in_reply_to_status_id_str     &lt;chr&gt; NA, NA, NA, "1437436224042635269", NA, N…</span>
<span class="co">#&gt; $ in_reply_to_user_id           &lt;dbl&gt; NA, NA, NA, 4.26e+08, NA, NA, NA, NA, 2.…</span>
<span class="co">#&gt; $ in_reply_to_user_id_str       &lt;chr&gt; NA, NA, NA, "426159377", NA, NA, NA, NA,…</span>
<span class="co">#&gt; $ in_reply_to_screen_name       &lt;chr&gt; NA, NA, NA, "MorganStanley", NA, NA, NA,…</span>
<span class="co">#&gt; $ geo                           &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ contributors                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ is_quote_status               &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE,…</span>
<span class="co">#&gt; $ retweet_count                 &lt;int&gt; 351, 124, 62, 0, 0, 0, 0, 0, 0, 0, 0, 1,…</span>
<span class="co">#&gt; $ favorite_count                &lt;int&gt; 3902, 898, 280, 0, 0, 0, 0, 0, 0, 7, 0, …</span>
<span class="co">#&gt; $ favorited                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…</span>
<span class="co">#&gt; $ retweeted                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…</span>
<span class="co">#&gt; $ lang                          &lt;chr&gt; "en", "en", "es", "en", "en", "en", "en"…</span>
<span class="co">#&gt; $ possibly_sensitive            &lt;lgl&gt; NA, FALSE, FALSE, FALSE, FALSE, FALSE, F…</span>
<span class="co">#&gt; $ quoted_status_id              &lt;dbl&gt; NA, NA, NA, NA, 1.44e+18, NA, NA, NA, NA…</span>
<span class="co">#&gt; $ quoted_status_id_str          &lt;chr&gt; NA, NA, NA, NA, "1442475408058830856", N…</span>
<span class="co">#&gt; $ text                          &lt;chr&gt; "If we call it Latinx Mass they can't ca…</span>
<span class="co">#&gt; $ favorited_by                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ display_text_width            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ retweeted_status              &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ quoted_status_permalink       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ query                         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span>
<span class="co">#&gt; $ possibly_sensitive_appealable &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …</span></code></pre></div>
<p>Now we have the 30 variables which can be written to disk as a plain-text file. Let’s go ahead a do this, but wrap it in a function that does all the work we’ve just laid out in one function. In addition we will check to see if the same query has been run, and skip running the query if the dataset is on disk.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">write_search_tweets</span> <span class="op">&lt;-</span> 
  <span class="kw">function</span><span class="op">(</span><span class="va">query</span>, <span class="va">path</span>, <span class="va">n</span> <span class="op">=</span> <span class="fl">100</span>, <span class="va">type</span> <span class="op">=</span> <span class="st">"mixed"</span>, <span class="va">include_rts</span> <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Function</span>
    <span class="co"># Conduct a Twitter search query and write the results to a csv file</span>
    
    <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co"># check to see if the file already exists</span>
      <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"File does not exist \n"</span><span class="op">)</span> <span class="co"># message</span>
      
      <span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://CRAN.R-project.org/package=rtweet">rtweet</a></span><span class="op">)</span> <span class="co"># to use Twitter API</span>
      <span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span> <span class="co"># to manipulate data</span>
      
      <span class="fu">auth_get</span><span class="op">(</span><span class="op">)</span> <span class="co"># get authentication token</span>
      
      <span class="va">results</span> <span class="op">&lt;-</span> <span class="co"># query results</span>
        <span class="fu"><a href="https://rdrr.io/pkg/rtweet/man/search_tweets.html">search_tweets</a></span><span class="op">(</span>q <span class="op">=</span> <span class="va">query</span>, <span class="co"># query term</span>
                      n <span class="op">=</span> <span class="va">n</span>, <span class="co"># number of tweets desired (default 100)</span>
                      type <span class="op">=</span> <span class="va">type</span>, <span class="co"># type of query</span>
                      include_rts <span class="op">=</span> <span class="va">include_rts</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>  <span class="co"># to include RTs</span>
        <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">!</span><span class="fu">where</span><span class="op">(</span><span class="va">is_list</span><span class="op">)</span><span class="op">)</span>  <span class="co"># remove list variables</span>
      
      <span class="kw">if</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.exists</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/basename.html">dirname</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co"># isolate directory and check if exists</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Creating directory \n"</span><span class="op">)</span> <span class="co"># message</span>
        
        <span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span><span class="op">(</span>path <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html">dirname</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span>, <span class="co"># isolate and create directory (remove file name)</span>
                   recursive <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># create embedded directories if necessary</span>
                   showWarnings <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="co"># do not report warnings</span>
      <span class="op">}</span>
      
      <span class="fu"><a href="https://readr.tidyverse.org/reference/write_delim.html">write_csv</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">results</span>, file <span class="op">=</span> <span class="va">path</span><span class="op">)</span> <span class="co"># write results to csv file </span>
      <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Twitter search results written to disk \n"</span><span class="op">)</span> <span class="co"># message</span>
      
    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
      <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"File already exists! \n"</span><span class="op">)</span> <span class="co"># message</span>
    <span class="op">}</span>
  <span class="op">}</span></code></pre></div>
<p>Let’s run this function with the same query as above.</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">write_search_tweets</span><span class="op">(</span>query <span class="op">=</span> <span class="st">"latinx"</span>, path <span class="op">=</span> <span class="st">"../data/original/twitter/rt_latinx.csv"</span><span class="op">)</span></code></pre></div>
<p>And the appropriate directory structure and file have been written to disk.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb54-1"><a href="acquire-data.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/original/twitter/</span></span>
<span id="cb54-2"><a href="acquire-data.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> rt_latinx.csv</span></code></pre></div>
<!-- 
Let's now look at a typical query using the `stream_tweets()` function. 


```r
rt_stream_usa <- stream_tweets(q = lookup_coords("usa"), timeout = 300)
```





The main difference to note here is that since we are pulling tweets posted in real-time, there is a `timeout` argument which we can set the number of seconds to leave the connection open (in this case 300 seconds is 5 minutes). Tweets that are posted during this window have a chance to be captured by our query (a 1\% chance from the Twitterverse). 

The second argument here specifies that the query is geolocation. The `stream_tweets()` function allows for one of four query types: 1. `q = ""` (default) where no parameters are specified, 2. a terms query, just like for `search_tweets()`, 3. a vector of user ids, and 4. geolocation coordinates, as seen above.

The geocoordinates above are generated by the `lookup_coords()` function. This function comes with a number of countries' and world cities' coordinates pre-determined and one can access them with the appropriate keyword. As we have just seen, `usa` is one such set of coordinates, `world` is another. To find the keywords for cities, you can browse the `rtweets:::citycoords` data frame.


```r
rtweet:::citycoords %>% # dataset
  filter(str_detect(city, "pho")) # filter by (partially) matching the city name
#> # A tibble: 3 × 3
#>   city              lat   lng
#>   <chr>           <dbl> <dbl>
#> 1 phoenix ariz     33.5  112.
#> 2 phoenix us       33.5  112.
#> 3 phoenix ariz us  33.5  112.
```

With the city name keyword identified, we can see the latitude/ longitude bounding box for this city. 


```r
lookup_coords("phoenix us")
#> $place
#> [1] "phoenix us"
#> 
#> $box
#> sw.lng.lng sw.lat.lat ne.lng.lng ne.lat.lat 
#>      112.0       33.4      112.1       33.5 
#> 
#> $point
#>   lat   lng 
#>  33.5 112.1 
#> 
#> attr(,"class")
#> [1] "coords" "list"
```

The `$box` coordinates are passed to `stream_tweets()` to gather real-time tweets. You can also  manually add the coordinates as well. There is a great website for getting the bounding box for any place on the planet appropriately named [Bounding Box](https://boundingbox.klokantech.com/).^[Just make sure to select CSV from the Copy and Paste dropdown and round to the nearest whole number.] -->
<!-- Consider:

- rtweet package for getting tweet data (Corona virus?)

Idea:



- RedditExtractoR
- googledrive

-->
<p>In sum, this subsection provided an overview to acquiring data from web service APIs through R packages. We took at closer look at the <code>gutenbergr</code> package which provides programmatic access to works available on Project Gutenberg and the <code>rtweet</code> package which provides authenticated access to Twitter. Working with package interfaces requires more knowledge of R including loading/ installing packages, working with vectors and data frames, and exporting data from an R session. We touched on these programming concepts and also outlined a method to create a reproducible workflow.</p>
</div>
</div>
<div id="web-scraping" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Web scraping<a class="anchor" aria-label="anchor" href="#web-scraping"><i class="fas fa-link"></i></a>
</h2>
<p>There are many resources available through manula and direct downloads from repositories and individual sites and R package interfaces to web resources with APIs, but these resources are relatively limited to the amount of public-facing textual data recorded on the web. In the case that you want to acquire data from webpages, R can be used to access the web programmatically through a process known as web scraping. The complexity of web scrapes can vary but in general it requires more advanced knowledge of R as well as the structure of the language of the web: HTML (Hypertext Markup Language).</p>
<div id="a-toy-example" class="section level3" number="5.3.1">
<h3>
<span class="header-section-number">5.3.1</span> A toy example<a class="anchor" aria-label="anchor" href="#a-toy-example"><i class="fas fa-link"></i></a>
</h3>
<p>HTML is a cousin of XML (eXtensible Markup Language) and as such organizes web documents in a hierarchical format that is read by your browser as you navigate the web. Take for example the toy webpage I created as a demonstration in Figure <a href="acquire-data.html#fig:ad-example-webpage">5.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-example-webpage"></span>
<img src="images/06-acquire-data/example-webpage.png" alt="Example web page." width="90%"><p class="caption">
Figure 5.3: Example web page.
</p>
</div>
<p>The file accessed by my browser to render this webpage is <code>test.html</code> and in plain-text format looks like this:</p>
<pre><code>
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;My website&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="intro"&gt;
      &lt;p&gt;Welcome!&lt;/p&gt;
      &lt;p&gt;This is my first website. &lt;/p&gt;
    &lt;/div&gt;
    &lt;table&gt;
      &lt;tr&gt;
        &lt;td&gt;Contact me:&lt;/td&gt;
        &lt;td&gt;
          &lt;a href="mailto:francojc@wfu.edu"&gt;francojc@wfu.edu&lt;/a&gt;
        &lt;/td&gt;
      &lt;/tr&gt;
    &lt;/table&gt;
    &lt;div class="conc"&gt;
      &lt;p&gt;Good-bye!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>Each element in this file is delineated by an opening and closing tag, <code>&lt;head&gt;&lt;/head&gt;</code>. Tags are nested within other tags to create the structural hierarchy. Tags can take class and id labels to distinguish them from other tags and often contain other attributes that dictate how the tag is to behave when rendered visually by a browser. For example, there are two <code>&lt;div&gt;</code> tags in our toy example: one has the label <code>class = "intro"</code> and the other <code>class = "conc"</code>. <code>&lt;div&gt;</code> tags are often used to separate sections of a webpage that may require special visual formatting. The <code>&lt;a&gt;</code> tag, on the other hand, creates a web link. As part of this tag’s function, it requires the attribute <code>href=</code> and a web protocol –in this case it is a link to an email address <code>mailto:francojc@wfu.edu</code>. More often than not, however, the <code>href=</code> contains a URL (Uniform Resource Locator). A working example might look like this: <code>&lt;a href="https://francojc.github.io/"&gt;My homepage&lt;/a&gt;</code>.</p>
<p>The aim of a web scrape is to download the HTML file, parse the document structure, and extract the elements containing the relevant information we wish to capture. Let’s attempt to extract some information from our toy example. To do this we will need the <a href="https://CRAN.R-project.org/package=rvest">rvest</a><span class="citation">(<a href="references.html#ref-R-rvest" role="doc-biblioref">Wickham, 2021</a>)</span> package. First, install/load the package, then, read and parse the HTML from the character vector named <code>web_file</code> assigning the result to <code>html</code>.</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">rvest</span><span class="op">)</span>  <span class="co"># install/ load `rvest`</span>

<span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">web_file</span><span class="op">)</span>  <span class="co"># read raw html and parse to xml</span>
<span class="va">html</span>
<span class="co">#&gt; {html_document}</span>
<span class="co">#&gt; &lt;html&gt;</span>
<span class="co">#&gt; [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...</span>
<span class="co">#&gt; [2] &lt;body&gt;\n    &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is  ...</span></code></pre></div>
<p><code>read_html()</code> parses the raw HTML into an object of class <code>xml_document</code>. The summary output above shows that tags the HTML structure have been parsed into ‘elements.’ The tag elements can be accessed by using the <code>html_elements()</code> function by specifying the tag to isolate.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div"</span><span class="op">)</span>
<span class="co">#&gt; {xml_nodeset (2)}</span>
<span class="co">#&gt; [1] &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is my first web ...</span>
<span class="co">#&gt; [2] &lt;div class="conc"&gt;\n      &lt;p&gt;Good-bye!&lt;/p&gt;\n    &lt;/div&gt;</span></code></pre></div>
<p>Notice that <code>html_elements("div")</code> has returned both <code>div</code> tags. To isolate one of tags by its class, we add the class name to the tag separating it with a <code>.</code>.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro"</span><span class="op">)</span>
<span class="co">#&gt; {xml_nodeset (1)}</span>
<span class="co">#&gt; [1] &lt;div class="intro"&gt;\n      &lt;p&gt;Welcome!&lt;/p&gt;\n      &lt;p&gt;This is my first web ...</span></code></pre></div>
<p>Great. Now say we want to drill down and isolate the subordinate <code>&lt;p&gt;</code> nodes. We can add <code>p</code> to our node filter.</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span>
<span class="co">#&gt; {xml_nodeset (2)}</span>
<span class="co">#&gt; [1] &lt;p&gt;Welcome!&lt;/p&gt;</span>
<span class="co">#&gt; [2] &lt;p&gt;This is my first website. &lt;/p&gt;</span></code></pre></div>
<p>To extract the text contained within a node we use the <code>html_text()</code> function.</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; [1] "Welcome!"                   "This is my first website. "</span></code></pre></div>
<p>The result is a character vector with two elements corresponding to the text contained in each <code>&lt;p&gt;</code> tag. If you were paying close attention you might have noticed that the second element in our vector includes extra whitespace after the period. To trim leading and trailing whitespace from text we can add the <code>trim = TRUE</code> argument to <code>html_text()</code>.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"div.intro p"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_text</span><span class="op">(</span>trim <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">#&gt; [1] "Welcome!"                  "This is my first website."</span></code></pre></div>
<p>From here we would then work to organize the text into a format we want to store it in and write the results to disk. Let’s leave writing data to disk for later in the chapter. For now keep our focus on working with <code>rvest</code> to acquire data from html documents working with a more practical example.</p>
</div>
<div id="a-practical-example" class="section level3" number="5.3.2">
<h3>
<span class="header-section-number">5.3.2</span> A practical example<a class="anchor" aria-label="anchor" href="#a-practical-example"><i class="fas fa-link"></i></a>
</h3>
<!-- update: change website to scrape -->
<!-- remember to remove `eval = FALSE` from code chunks to run -->
<p>With some basic understanding of HTML and how to use the <code>rvest</code> package, let’s turn to a realistic example. Say we want to acquire lyrics from the online music website and database <a href="https://www.last.fm/">last.fm</a>. The first step in any web scrape is to investigate the site and page(s) we want to scrape to ascertain if there any licensing restrictions. Many, but not all websites, will include a plain text file <a href="https://www.cloudflare.com/learning/bots/what-is-robots.txt/"><code>robots.txt</code></a> at the root of the main URL. This file is declares which webpages a ‘robot’ (including web scraping scripts) can and cannot access. We can use the <code>robotstxt</code> package to find out which URLs are accessible.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;It is important to check the paths of sub-domains as some website allow access in some areas and not in others&lt;/p&gt;"><sup>18</sup></a></p>
<!-- change domain -->
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">robotstxt</span><span class="op">)</span>  <span class="co"># load/ install `robotstxt`</span>

<span class="fu">paths_allowed</span><span class="op">(</span>paths <span class="op">=</span> <span class="st">"https://www.last.fm/"</span><span class="op">)</span>  <span class="co"># check permissions</span>
<span class="co">#&gt; [1] TRUE</span></code></pre></div>
<!-- screenshot of page to scrape -->
<p>The next step includes identifying the URL we want to target and exploring the structure of the HTML document. Take the following webpage I have identified, seen in Figure <a href="acquire-data.html#fig:ad-example-lyrics-page-lastfm">5.4</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-example-lyrics-page-lastfm"></span>
<img src="images/06-acquire-data/ad-lastfm-webpage-lyrics.png" alt="Lyrics page from last.fm" width="90%"><p class="caption">
Figure 5.4: Lyrics page from last.fm
</p>
</div>
<p>As in our toy example, first we want to feed the HTML web address to the <code>read_html()</code> function to parse the tags into elements. We will then assign the result to <code>html</code>.</p>
<!-- rvest::read_html() -->
<!-- show code, but don't evaluate -->
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># read and parse html as an xml object</span>
<span class="va">lyrics_url</span> <span class="op">&lt;-</span> <span class="st">"https://www.last.fm/music/Radiohead/_/Karma+Police/+lyrics"</span>
<span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span>  <span class="co"># read raw html and parse to xml</span>
<span class="va">html</span></code></pre></div>
<!-- show html object -->
<pre><code>#&gt; {html_document}
#&gt; &lt;html lang="en" class="
#&gt;         no-js
#&gt;         playbar-masthead-release-shim
#&gt;         youtube-provider-not-ready
#&gt;     "&gt;
#&gt; [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
#&gt; [2] &lt;body&gt;\n&lt;div id="initial-tealium-data" data-require="tracking/tealium-uta ...</code></pre>
<p>At this point we have captured and parsed the raw HTML assigning it to the object named <code>html</code>. The next step is to identify the html elements that contain the information we want to extract from the page. To do this it is helpful to use a browser to inspect specific elements of the webpage. Your browser will be equipped with a command that you can enable by hovering your mouse over the element of the page you want to target and using a right click to select “Inspect” (Chrome) or “Inspect Element” (Safari, Brave). This will split your browser window vertical or horizontally showing you the raw HTML underlying the webpage.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-inspect-element-artist-lastfm"></span>
<img src="images/06-acquire-data/ad-lastfm-artist-inspect.png" alt='Using the "Inspect Element" command to explore raw html.' width="90%"><p class="caption">
Figure 5.5: Using the “Inspect Element” command to explore raw html.
</p>
</div>
<!-- change class/ tag/ attribute appropriately -->
<p>From Figure <a href="acquire-data.html#fig:ad-inspect-element-lyrics-lastfm">5.6</a> we see that the element we want to target is contained within an <code>&lt;a&gt;&lt;/a&gt;</code> tag. Now this tag is common and we don’t want to extract every <code>a</code> so we use the class <code>header-new-crumb</code> to specify we only want the artist name. Using the convention described in our toy example, we can isolate the artist of the lyrics page.</p>
<!-- change class/ tag/ attribute appropriately -->
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span>
<span class="co">#&gt; {html_node}</span>
<span class="co">#&gt; &lt;a class="header-new-crumb" itemprop="url" href="/music/Radiohead"&gt;</span>
<span class="co">#&gt; [1] &lt;span itemprop="name"&gt;Radiohead&lt;/span&gt;</span></code></pre></div>
<p>We can then extract the text with <code>html_text()</code>.</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">artist</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>
<span class="va">artist</span>
<span class="co">#&gt; [1] "Radiohead"</span></code></pre></div>
<p>Let’s extract the song title in the same way.</p>
<!-- change class/ tag/ attribute appropriately -->
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">song</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_element</span><span class="op">(</span><span class="st">"h1.header-new-title"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>
<span class="va">song</span>
<span class="co">#&gt; [1] "Karma Police"</span></code></pre></div>
<p>Now if we inspect the HTML of the lyrics page, we will notice that the lyrics are contained in <code>&lt;p&gt;&lt;/p&gt;</code> tags with the class <code>lyrics-paragraph</code>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-inspect-element-lyrics-lastfm"></span>
<img src="images/06-acquire-data/ad-lastfm-lyrics-inspect.png" alt='Using the "Inspect Element" command to explore raw html.' width="90%"><p class="caption">
Figure 5.6: Using the “Inspect Element” command to explore raw html.
</p>
</div>
<p>Since there are multiple elements that we want to extract, we will need to use the <code>html_elements()</code> function instead of the <code>html_element()</code> which only targets one element.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lyrics</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"p.lyrics-paragraph"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>
<span class="va">lyrics</span>
<span class="co">#&gt; [1] "Karma policeArrest this manHe talks in mathsHe buzzes like a fridgeHe's like a detuned radio"      </span>
<span class="co">#&gt; [2] "Karma policeArrest this girlHer Hitler hairdoIs making me feel illAnd we have crashed her party"   </span>
<span class="co">#&gt; [3] "This is what you'll getThis is what you'll getThis is what you'll getWhen you mess with us"        </span>
<span class="co">#&gt; [4] "Karma policeI've given all I canIt's not enoughI've given all I canBut we're still on the payroll" </span>
<span class="co">#&gt; [5] "This is what you'll getThis is what you'll getThis is what you'll getWhen you mess with us"        </span>
<span class="co">#&gt; [6] "For a minute thereI lost myself, I lost myselfPhew, for a minute thereI lost myself, I lost myself"</span>
<span class="co">#&gt; [7] "For a minute thereI lost myself, I lost myselfPhew, for a minute thereI lost myself, I lost myself"</span></code></pre></div>
<p>At this point, we have isolated and extracted the artist, song, and lyrics from the webpage. Each of these elements are stored in character vectors in our R session. To complete our task we need to write this data to disk as plain text. With an eye towards a tidy dataset, an ideal format to store the data is in a CSV file where each column corresponds to one of the elements from our scrape and each row an observation. A CSV file is a tabular format and so before we can write the data to disk let’s coerce the data that we have into tabular format. We will use the <code><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble()</a></code> function here to streamline our data frame creation.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;&lt;code&gt;tibble&lt;/code&gt; objects are &lt;code&gt;data.frame&lt;/code&gt; objects with some added extra bells and whistles that we won’t get into here.&lt;/p&gt;"><sup>19</sup></a> Feeding each of the vectors <code>artist</code>, <code>song</code>, and <code>lyrics</code> as arguments to <code><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble()</a></code> creates the tabular format we are looking for.</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu"><a href="https://pillar.r-lib.org/reference/glimpse.html">glimpse</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; Rows: 7</span>
<span class="co">#&gt; Columns: 3</span>
<span class="co">#&gt; $ artist &lt;chr&gt; "Radiohead", "Radiohead", "Radiohead", "Radiohead", "Radiohead"…</span>
<span class="co">#&gt; $ song   &lt;chr&gt; "Karma Police", "Karma Police", "Karma Police", "Karma Police",…</span>
<span class="co">#&gt; $ lyrics &lt;chr&gt; "Karma policeArrest this manHe talks in mathsHe buzzes like a f…</span></code></pre></div>
<p>Notice that there are seven rows in this data frame, one corresponding to each paragraph in <code>lyrics</code>. R has a bias towards working with vectors of the same length. As such each of the other vectors (<code>artist</code>, and <code>song</code>) are replicated, or recycled, until they are the same length as the longest vector <code>lyrics</code>, which a length of seven.</p>
<p>For good documentation let’s add our object <code>lyrics_url</code> to the data frame, which contains the actual web link to this page, and assign the result to <code>song_lyrics</code>.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">song_lyrics</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span>, <span class="va">lyrics_url</span><span class="op">)</span></code></pre></div>
<p>The final step is to write this data to disk. To do this we will use the <code><a href="https://readr.tidyverse.org/reference/write_delim.html">write_csv()</a></code> function.</p>
<!-- adjust target file -->
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://readr.tidyverse.org/reference/write_delim.html">write_csv</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">song_lyrics</span>, path <span class="op">=</span> <span class="st">"../data/original/lyrics.csv"</span><span class="op">)</span></code></pre></div>
</div>
<div id="scaling-up" class="section level3" number="5.3.3">
<h3>
<span class="header-section-number">5.3.3</span> Scaling up<a class="anchor" aria-label="anchor" href="#scaling-up"><i class="fas fa-link"></i></a>
</h3>
<p>At this point you may be think, ‘Great, I can download data from a single page, but what about downloading multiple pages?’ Good question. That’s really where the strength of a programming approach takes hold. Extracting information from multiple pages is not fundamentally different than working with a single page. However, it does require more sophisticated understanding of the web and R coding strategies, in particular <strong>iteration</strong>.</p>
<p>Before we get to iteration, let’s first create a couple functions to make it possible to efficiently reuse the code we have developed so far:</p>
<ol style="list-style-type: decimal">
<li>the <code>get_lyrics</code> function wraps the code for scraping a single lyrics webpage from last.fm.</li>
</ol>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">get_lyrics</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Function: Scrape last.fm lyrics page for: artist, song, and lyrics from a</span>
    <span class="co"># provided content link.  Return as a tibble/data.frame</span>

    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Scraping song lyrics from:"</span>, <span class="va">lyrics_url</span>, <span class="st">"\n"</span><span class="op">)</span>

    <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">rvest</span><span class="op">)</span>  <span class="co"># install/ load package(s)</span>

    <span class="va">url</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span><span class="va">lyrics_url</span>, <span class="st">"rb"</span><span class="op">)</span>  <span class="co"># open url connection </span>
    <span class="va">html</span> <span class="op">&lt;-</span> <span class="fu">read_html</span><span class="op">(</span><span class="va">url</span><span class="op">)</span>  <span class="co"># read and parse html as an xml object</span>
    <span class="fu"><a href="https://rdrr.io/r/base/connections.html">close</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span>  <span class="co"># close url connection</span>

    <span class="va">artist</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_element</span><span class="op">(</span><span class="st">"a.header-new-crumb"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>

    <span class="va">song</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_element</span><span class="op">(</span><span class="st">"h1.header-new-title"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>

    <span class="va">lyrics</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_elements</span><span class="op">(</span><span class="st">"p.lyrics-paragraph"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
        <span class="fu">html_text</span><span class="op">(</span><span class="op">)</span>

    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"...one moment "</span><span class="op">)</span>

    <span class="fu"><a href="https://rdrr.io/r/base/Sys.sleep.html">Sys.sleep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>  <span class="co"># sleep for 1 second to reduce server load</span>

    <span class="va">song_lyrics</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span><span class="va">artist</span>, <span class="va">song</span>, <span class="va">lyrics</span>, <span class="va">lyrics_url</span><span class="op">)</span>

    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"... done! \n"</span><span class="op">)</span>

    <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">song_lyrics</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>

<div class="rmdtip">
<p>The <code>get_lyrics</code> function includes all of the code developed previously, but also includes: (1) output messages (<code><a href="https://rdrr.io/r/base/cat.html">cat()</a></code>), (2) a processing pause (<code><a href="https://rdrr.io/r/base/Sys.sleep.html">Sys.sleep()</a></code>), and (3) code to manage opening and closing web connections (<code><a href="https://rdrr.io/r/base/connections.html">url()</a></code> and <code><a href="https://rdrr.io/r/base/connections.html">close()</a></code>).</p>
Points (1) and (2) will be useful when we iterate over this function to provide status messages and to reduce server load when processing multiple webpages from a web domain. (3) will be necessary to manage webpages that are non-existent. As we will see, we will generate url link to multiple song lyrics some of which will not be valid. To avoid errors that will stop the processing these steps have been incorporated here.
</div>
<ol start="2" style="list-style-type: decimal">
<li>the <code>write_content</code> writes the webscraped data to our local machine, including functionality to create the necessary directory structure of the target file path we choose.</li>
</ol>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">write_content</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">content</span>, <span class="va">target_file</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Function: Write the tibble content to disk. Create the directory if it</span>
    <span class="co"># does not already exist.</span>

    <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span><span class="op">)</span>  <span class="co"># install/ load packages</span>

    <span class="va">target_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html">dirname</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span>  <span class="co"># identify target file directory structure</span>
    <span class="fu"><a href="https://rdrr.io/r/base/files2.html">dir.create</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">target_dir</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span>, showWarnings <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>  <span class="co"># create directory</span>
    <span class="fu"><a href="https://readr.tidyverse.org/reference/write_delim.html">write_csv</a></span><span class="op">(</span><span class="va">content</span>, <span class="va">target_file</span><span class="op">)</span>  <span class="co"># write csv file to target location</span>

    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Content written to disk!\n"</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>With just these two functions, we can take a lyrics URL from last.fm and scrape and write the data to disk like this.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lyrics_url</span> <span class="op">&lt;-</span> <span class="st">"https://www.last.fm/music/Pixies/_/Where+Is+My+Mind%3F/+lyrics"</span>

<span class="va">lyrics_url</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">get_lyrics</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
    <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/lyrics.csv"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb75"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb75-1"><a href="acquire-data.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/original/lastfm/</span></span>
<span id="cb75-2"><a href="acquire-data.html#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> lyrics.csv</span></code></pre></div>
<p>Now we could manually search and copy URLs and run this function pipeline. This would be fine if we had just a few particular URLs that we wanted to scrape. But if we want to, say, scrape a set of lyrics grouped by genre. We would probably want a more programmatic approach. The good news is we can leverage our understanding of webscraping to scrape last.fm to harvest the information needed to create and store links to songs by genre. We can then pass these links to a pipeline, similar to the previous one, to scrape lyrics for many songs and store the results in files grouped by genre.</p>
<p>Last.fm provides a genres page where some of the top genres are listed and can be further explored.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-genre-page-lastfm"></span>
<img src="images/06-acquire-data/ad-lastfm-genres.png" alt="Genre page on last.fm" width="90%"><p class="caption">
Figure 5.7: Genre page on last.fm
</p>
</div>
<p>Diving into a a particular genre, ‘rock’ for example, you will get a listing of the top tracks in that genre.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ad-genre-tracks-list-lastfm"></span>
<img src="images/06-acquire-data/ad-lastfm-genre-tracks-list.png" alt="Tracks by genre list page on last.fm" width="90%"><p class="caption">
Figure 5.8: Tracks by genre list page on last.fm
</p>
</div>
<p>If we inspect the HTML elements for the track names in Figure <a href="acquire-data.html#fig:ad-genre-tracks-list-lastfm">5.8</a>, we can see that a relative URL is found for the track. In this case, I have ‘Smells Like Teen Spirit’ by Nirvana highlighted in the inspector. If we follow this link to the track page and then to the lyrics for the track, you will notice that the relative URL on the track listings page has all the unique information. Only the web domain <code>https://www.last.fm</code> and the post-pended <code>/+lyrics</code> is missing.</p>
<p>So with this we can put together a function which gets the track listing for a last.fm genre, scrapes the relative URLs for each of the tracks, and creates a full absolute URL to the lyrics page.</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">get_genre_lyrics_urls</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">last_fm_genre</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># Function: Scrapes a given last.fm genre title for top tracks in</span>
  <span class="co"># that genre and then creates links to the lyrics pages for these tracks</span>
  
  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Scraping top songs from:"</span>, <span class="va">last_fm_genre</span>, <span class="st">"genre: \n"</span><span class="op">)</span>
  
  <span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">tidyverse</span>, <span class="va">rvest</span><span class="op">)</span> <span class="co"># install/ load packages</span>
  
  <span class="co"># create web url for the genre listing page</span>
  <span class="va">genre_listing_url</span> <span class="op">&lt;-</span> 
    <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"https://www.last.fm/tag/"</span>, <span class="va">last_fm_genre</span>, <span class="st">"/tracks"</span><span class="op">)</span> 
  
  <span class="va">genre_lyrics_urls</span> <span class="op">&lt;-</span> 
    <span class="fu">read_html</span><span class="op">(</span><span class="va">genre_listing_url</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># read raw html and parse to xml</span>
    <span class="fu">html_elements</span><span class="op">(</span><span class="st">"td.chartlist-name a"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># isolate the track elements</span>
    <span class="fu">html_attr</span><span class="op">(</span><span class="st">"href"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># extract the href attribute</span>
    <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"https://www.last.fm"</span>, <span class="va">.</span>, <span class="st">"/+lyrics"</span><span class="op">)</span> <span class="co"># join the domain, relative artist path, and the post-pended /+lyrics to create an absolute URL</span>
  
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">genre_lyrics_urls</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>With this function, all we need is to identify the verbatim way last.fm lists the genres. For Rock, it is <code>rock</code> but for Hip Hop, it is <code>hip+hop</code>.</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>  <span class="co"># get urls for top hip hop tracks</span>
  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="co"># only display 10 tracks</span></code></pre></div>
<pre><code>#&gt; Scraping top songs from: hip+hop genre:
#&gt;  [1] "https://www.last.fm/music/Juzhin/_/Charlie+Conscience+(feat.+MMAIO)/+lyrics"
#&gt;  [2] "https://www.last.fm/music/Juzhin/_/Railways/+lyrics"                        
#&gt;  [3] "https://www.last.fm/music/Juzhin/_/Coming+Down/+lyrics"                     
#&gt;  [4] "https://www.last.fm/music/Juzhin/_/Tupona/+lyrics"                          
#&gt;  [5] "https://www.last.fm/music/Juzhin/_/Sakhalin/+lyrics"                        
#&gt;  [6] "https://www.last.fm/music/Juzhin/_/3+Simple+Minutes/+lyrics"                
#&gt;  [7] "https://www.last.fm/music/Juzhin/_/Lost+Sense/+lyrics"                      
#&gt;  [8] "https://www.last.fm/music/Juzhin/_/Wonderful/+lyrics"                       
#&gt;  [9] "https://www.last.fm/music/Gina+Moryson/_/Vanilla+Smoothy+(Live)/+lyrics"    
#&gt; [10] "https://www.last.fm/music/Juzhin/_/Flunk-Down+(Juzhin+Remix)/+lyrics"</code></pre>
<p>So now we have a method to scrape URLs by genre and list them in a vector. Our approach, then, could be to pass these lyrics URLs to our existing pipeline which downloads the lyrics (<code>get_lyrics()</code>) and then writes them to disk (<code>write_content()</code>).</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Note: will not run</span>
<span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># get lyrics urls for specific genre</span>
  <span class="fu">get_lyrics</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># scrape lyrics url</span>
  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></code></pre></div>
<p>This approach, however, has a couple problems. (1) our <code>get_lyrics()</code> function only takes one URL at a time, but the result of <code>get_genre_lyrics_urls()</code> will produce many URLs. We will be able to solve this with iteration using the <a href="">purrr</a> package, specifically the <code><a href="https://purrr.tidyverse.org/reference/map.html">map()</a></code> function which will iteratively map each URL output from <code>get_genre_lyrics_urls()</code> to <code>get_lyrics()</code> in turn. (2) the output from our iterative application of <code>get_lyrics()</code> will produce a tibble for each URL, which then sets up a problem with writing the tibbles to disk with the <code>write_content()</code> function. To avoid this we will want to combine the tibbles into one single tibble and then send it to be written to disk. The <code><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows()</a></code> function will do just this.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Note: will run, but with occasional errors</span>
<span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># get lyrics urls for specific genre</span>
  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">get_lyrics</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>  <span class="co"># scrape lyrics url</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># combine tibbles into one</span>
  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></code></pre></div>
<p>This preceding pipeline conceptually will work. However, on my testing, it turns out that some of the URLs that are generated in the <code>get_genre_lyrics_urls()</code> do not exist on the site. That is, the song is listed but no lyrics have been added to the song site. This will mean that when the URL is sent to the <code>get_lyrics()</code> function, there will be an error when attempting to download and parse the page with <code>read_html()</code> which will halt the entire process. To avoid this error, we can wrap the <code>get_lyrics()</code> function in a function designed to attempt to download and parse the URL (<code><a href="https://rdrr.io/r/base/conditions.html">tryCatch()</a></code>), but if there is an error, it will skip it and move on to the next URL without stopping the processing. This approach is reflected in the <code>get_lyrics_catch()</code> function below.</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Wrap the `get_lyrics()` function with `tryCatch()` to skip URLs that have no</span>
<span class="co"># lyrics</span>

<span class="va">get_lyrics_catch</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span> <span class="op">{</span>
    <span class="kw"><a href="https://rdrr.io/r/base/conditions.html">tryCatch</a></span><span class="op">(</span><span class="fu">get_lyrics</span><span class="op">(</span><span class="va">lyrics_url</span><span class="op">)</span>, error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span><span class="op">)</span>  <span class="co"># no, URL, return(NULL)/ skip</span>
<span class="op">}</span></code></pre></div>
<p>Updating the pipeline with the <code>get_lyrics_catch()</code> function would look like this:</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Note: will run, but we can do better</span>
<span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="st">"hip+hop"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># get lyrics urls for specific genre</span>
  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">get_lyrics_catch</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>  <span class="co"># scrape lyrics url</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># combine tibbles into one</span>
  <span class="fu">write_content</span><span class="op">(</span>target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span> <span class="co"># write to disk</span></code></pre></div>
<p>This will work, but as we have discussed before one of this goals we have we acquiring data for a reproducible research project is to make sure that we are developing efficient code that will not burden site’s server we are scraping from. In this case, we would like to check to see if the data is already downloaded. If not, then the script should run. If so, then the script does not run. Of course this is a perfect use of a conditional statement. To make this a single function we can call, I’ve wrapped the functions we created for getting lyric URLs from last.fm, scraping the URLs, and writing the results to disk in the <code>download_lastfm_lyrics()</code> function below. I also added a line to add a <code>last_fm_genre</code> column to the combined tibble to store the name of the genre we scraped (i.e. <code>mutate(genre = last_fm_genre)</code>.</p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">download_lastfm_lyrics</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">last_fm_genre</span>, <span class="va">target_file</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Function: get last.fm lyric urls by genre and write them to disk</span>

    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>

        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Downloading data.\n"</span><span class="op">)</span>

        <span class="fu">get_genre_lyrics_urls</span><span class="op">(</span><span class="va">last_fm_genre</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
            <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">get_lyrics_catch</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
            <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
            <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>genre <span class="op">=</span> <span class="va">last_fm_genre</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
            <span class="fu">write_content</span><span class="op">(</span><span class="va">target_file</span><span class="op">)</span>

    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Data already downloaded!\n"</span><span class="op">)</span>
    <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Now we can call this function on any genre on the last.fm site and download the top 50 song lyrics for that genre (provided they all have lyrics pages).</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Scrape lyrics for 'pop'</span>
<span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"pop"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/pop.csv"</span><span class="op">)</span>

<span class="co"># Scrape lyrics for 'rock'</span>
<span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"rock"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/rock.csv"</span><span class="op">)</span>

<span class="co"># Scrape lyrics for 'hip hop'</span>
<span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"hip+hop"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/hip_hop.csv"</span><span class="op">)</span>

<span class="co"># Scrape lyrics for 'metal'</span>
<span class="fu">download_lastfm_lyrics</span><span class="op">(</span>last_fm_genre <span class="op">=</span> <span class="st">"metal"</span>, target_file <span class="op">=</span> <span class="st">"../data/original/lastfm/metal.csv"</span><span class="op">)</span></code></pre></div>
<p>Now we can see that our web scrape data is organized in a similar fashion to the other data we acquired in this chapter.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb85-1"><a href="acquire-data.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb85-2"><a href="acquire-data.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived/</span>
<span id="cb85-3"><a href="acquire-data.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original/</span>
<span id="cb85-4"><a href="acquire-data.html#cb85-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> cedel2/</span>
<span id="cb85-5"><a href="acquire-data.html#cb85-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── texts.csv</span>
<span id="cb85-6"><a href="acquire-data.html#cb85-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> gutenberg/</span>
<span id="cb85-7"><a href="acquire-data.html#cb85-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── works_pq.csv</span>
<span id="cb85-8"><a href="acquire-data.html#cb85-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── works_pr.csv</span>
<span id="cb85-9"><a href="acquire-data.html#cb85-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> lastfm/</span>
<span id="cb85-10"><a href="acquire-data.html#cb85-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── country.csv</span>
<span id="cb85-11"><a href="acquire-data.html#cb85-11" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── hip_hop.csv</span>
<span id="cb85-12"><a href="acquire-data.html#cb85-12" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── lyrics.csv</span>
<span id="cb85-13"><a href="acquire-data.html#cb85-13" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── metal.csv</span>
<span id="cb85-14"><a href="acquire-data.html#cb85-14" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── pop.csv</span>
<span id="cb85-15"><a href="acquire-data.html#cb85-15" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── rock.csv</span>
<span id="cb85-16"><a href="acquire-data.html#cb85-16" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc/</span>
<span id="cb85-17"><a href="acquire-data.html#cb85-17" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── meta-data/</span>
<span id="cb85-18"><a href="acquire-data.html#cb85-18" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcriptions/</span>
<span id="cb85-19"><a href="acquire-data.html#cb85-19" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> scs/</span>
<span id="cb85-20"><a href="acquire-data.html#cb85-20" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── README</span>
<span id="cb85-21"><a href="acquire-data.html#cb85-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── discourse</span>
<span id="cb85-22"><a href="acquire-data.html#cb85-22" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── disfluency</span>
<span id="cb85-23"><a href="acquire-data.html#cb85-23" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── documentation/</span>
<span id="cb85-24"><a href="acquire-data.html#cb85-24" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── tagged</span>
<span id="cb85-25"><a href="acquire-data.html#cb85-25" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   ├── timed-transcript</span>
<span id="cb85-26"><a href="acquire-data.html#cb85-26" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│</span>   └── transcript</span>
<span id="cb85-27"><a href="acquire-data.html#cb85-27" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> twitter/</span>
<span id="cb85-28"><a href="acquire-data.html#cb85-28" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> rt_latinx.csv</span></code></pre></div>
<p>Again, it is important to add these custom functions to our <code>acquire_functions.R</code> script in the <code>functions/</code> directory so we can access them in our scripts more efficiently and make our analysis steps more succinct and legible.</p>
<p>In this section we covered scraping language data from the web. The rvest package provides a host of functions for downloading and parsing HTML. We first looked at a toy example to get a basic understanding of how HTML works and then moved to applying this knowledge to a practical example. To maintain a reproducible workflow, the code developed in this example was grouped into task-oriented functions which were in turn joined and wrapped into a function that provided convenient access to our workflow and avoided unnecessary downloads (in the case the data already exists on disk).</p>
<p>Here we have built on previously introduced R coding concepts and demonstrated various others. Web scraping often requires more knowledge of and familiarity with R as well as other web technologies. Rest assured, however, practice will increase confidence in your abilities. I encourage you to practice on your own with other websites. You will encounter problems. Consult the R documentation in RStudio or online and lean on the R community on the web at sites such as <a href="https://stackoverflow.com/">Stack Overflow</a> inter alia.</p>
</div>
</div>
<div id="documentation-1" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Documentation<a class="anchor" aria-label="anchor" href="#documentation-1"><i class="fas fa-link"></i></a>
</h2>
<p>As part of the data acquisition process it is important include documentation that describes the data resource(s) that will serve as the base for a research project. For all resources the data should include as much information possible that outlines the sampling frame of the data <span class="citation">(<a href="references.html#ref-Adel2020" role="doc-biblioref">Ädel, 2020</a>)</span>. For a corpus sample acquired from a repository will often include documentation which will outline the sampling frame –this most likely will be the very information which leads a researcher to select this resource for the project at hand. It is important to include this documentation (HTML or PDF file) or reference to the documentation (article citation or link<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Note that web links can change and it is often best to safeguard the documentation by downloading the HTML documentation page instead of linking&lt;/p&gt;"><sup>20</sup></a>) within the reproducible project’s directory structure.</p>
<p>In other cases where the data acquisition process is formulated and conducted by the researcher for the specific aims of the research (i.e. API and web scraping approaches), the researcher should make an effort to document those aspects which are key for the study, but that may also be of interest to other researchers for similar research questions. This will may include language characteristics such as modality, register, genre, etc., speaker/ writer characteristics such as demographics, time period(s), context of the linguistic communication, etc. and process characteristics such as the source of the data, the process of acquisition, date of acquisition, etc. However, it is important to recognize that each language sample and the resource from which it is drawn is unique. As a general rule of thumb, a researcher should document the resource as if this were a resource <em>they</em> were to encounter for the first time. To archive this information, it is standard practice to include a <code>README</code> file in the relevant directory where the data is stored.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb86-1"><a href="acquire-data.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="ex">data/</span></span>
<span id="cb86-2"><a href="acquire-data.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="ex">├──</span> derived/</span>
<span id="cb86-3"><a href="acquire-data.html#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="ex">└──</span> original/</span>
<span id="cb86-4"><a href="acquire-data.html#cb86-4" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> cedel2/</span>
<span id="cb86-5"><a href="acquire-data.html#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── documentation/</span>
<span id="cb86-6"><a href="acquire-data.html#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── texts.csv</span>
<span id="cb86-7"><a href="acquire-data.html#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> gutenberg/</span>
<span id="cb86-8"><a href="acquire-data.html#cb86-8" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── README.md</span>
<span id="cb86-9"><a href="acquire-data.html#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── works_pq.csv</span>
<span id="cb86-10"><a href="acquire-data.html#cb86-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── works_pr.csv</span>
<span id="cb86-11"><a href="acquire-data.html#cb86-11" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> lastfm/</span>
<span id="cb86-12"><a href="acquire-data.html#cb86-12" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── README.md</span>
<span id="cb86-13"><a href="acquire-data.html#cb86-13" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── country.csv</span>
<span id="cb86-14"><a href="acquire-data.html#cb86-14" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── hip_hop.csv</span>
<span id="cb86-15"><a href="acquire-data.html#cb86-15" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── lyrics.csv</span>
<span id="cb86-16"><a href="acquire-data.html#cb86-16" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── metal.csv</span>
<span id="cb86-17"><a href="acquire-data.html#cb86-17" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── pop.csv</span>
<span id="cb86-18"><a href="acquire-data.html#cb86-18" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── rock.csv</span>
<span id="cb86-19"><a href="acquire-data.html#cb86-19" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> sbc/</span>
<span id="cb86-20"><a href="acquire-data.html#cb86-20" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── meta-data/</span>
<span id="cb86-21"><a href="acquire-data.html#cb86-21" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── transcriptions/</span>
<span id="cb86-22"><a href="acquire-data.html#cb86-22" aria-hidden="true" tabindex="-1"></a>    <span class="ex">├──</span> scs/</span>
<span id="cb86-23"><a href="acquire-data.html#cb86-23" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── README</span>
<span id="cb86-24"><a href="acquire-data.html#cb86-24" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── discourse</span>
<span id="cb86-25"><a href="acquire-data.html#cb86-25" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── disfluency</span>
<span id="cb86-26"><a href="acquire-data.html#cb86-26" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── documentation/</span>
<span id="cb86-27"><a href="acquire-data.html#cb86-27" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── tagged</span>
<span id="cb86-28"><a href="acquire-data.html#cb86-28" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> ├── timed-transcript</span>
<span id="cb86-29"><a href="acquire-data.html#cb86-29" aria-hidden="true" tabindex="-1"></a>    <span class="ex">│  </span> └── transcript</span>
<span id="cb86-30"><a href="acquire-data.html#cb86-30" aria-hidden="true" tabindex="-1"></a>    <span class="ex">└──</span> twitter/</span>
<span id="cb86-31"><a href="acquire-data.html#cb86-31" aria-hidden="true" tabindex="-1"></a>        <span class="ex">├──</span> README.md</span>
<span id="cb86-32"><a href="acquire-data.html#cb86-32" aria-hidden="true" tabindex="-1"></a>        <span class="ex">└──</span> rt_latinx.csv</span></code></pre></div>
<p>For both existing corpora and data samples acquired by the researcher it is also important to signal if there are conditions and/ or licensing restrictions that one should heed when using and potentially sharing the data. In some cases existing corpus data come with restrictions on data sharing. These can be quite restrictive and ultimately require that the corpus data not be included in publically available reproducible project or data can only be shared in a derived format. If this the case, it is important to document the steps to legally acquire the data so that a researcher can acquire their own license and take full advantage of your reproducible project.</p>
<p>In the case of data from APIs or web scraping, there too may be stipulations on sharing data. A growing number of data sources apply one of <a href="https://creativecommons.org/about/cclicenses/">the available Creative Common Licenses</a>. Check the source of your data for more information and if you are a member of a research institution you will likely have a <a href="https://zsr.wfu.edu/digital-scholarship/copyright/">specialist</a> on <a href="https://www.copyright.gov/fair-use/more-info.html">Copyright and Fair Use</a>.</p>
</div>
<div id="summary-4" class="section level2 unnumbered">
<h2>Summary<a class="anchor" aria-label="anchor" href="#summary-4"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter we have covered a lot of ground. On the surface we have discussed three methods for acquiring corpus data for use in text analysis. In the process we have delved into various aspects of the R programming language. Some key concepts include writing custom functions and working with those function in an iterative manner. We have also considered topics that are more general in nature and concern interacting with data found on the internet.</p>
<p>Each of these methods should be approached in a way that is transparent to the researcher and to would-be collaborators and the general research community. For this reason the documentation of the steps taken to acquire data are key both in the code and in human-facing documentation.</p>
<p>At this point you have both a bird’s eye view of the data available on the web and strategies on how to access a great majority of it. It is now time to turn to the next step in our data analysis project: data curation. In the next posts I will cover how to wrangle your raw data into a tidy dataset. This will include working with and incorporating meta-data as well as augmenting a dataset with linguistic annotations.</p>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="preparation-overview.html">Overview</a></div>
<div class="next"><a href="curate-data.html"><span class="header-section-number">6</span> Curate data</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#acquire-data"><span class="header-section-number">5</span> Acquire data</a></li>
<li>
<a class="nav-link" href="#downloads"><span class="header-section-number">5.1</span> Downloads</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#manual"><span class="header-section-number">5.1.1</span> Manual</a></li>
<li><a class="nav-link" href="#programmatic"><span class="header-section-number">5.1.2</span> Programmatic</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#apis"><span class="header-section-number">5.2</span> APIs</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#open-access"><span class="header-section-number">5.2.1</span> Open access</a></li>
<li><a class="nav-link" href="#authentication"><span class="header-section-number">5.2.2</span> Authentication</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#web-scraping"><span class="header-section-number">5.3</span> Web scraping</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-toy-example"><span class="header-section-number">5.3.1</span> A toy example</a></li>
<li><a class="nav-link" href="#a-practical-example"><span class="header-section-number">5.3.2</span> A practical example</a></li>
<li><a class="nav-link" href="#scaling-up"><span class="header-section-number">5.3.3</span> Scaling up</a></li>
</ul>
</li>
<li><a class="nav-link" href="#documentation-1"><span class="header-section-number">5.4</span> Documentation</a></li>
<li><a class="nav-link" href="#summary-4">Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/lin380/coursebook/blob/master/06-acquire-data.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/lin380/coursebook/edit/master/06-acquire-data.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Coursebook</strong>: Text as Data: An introduction to quantitative text analysis and reproducible research with R" was written by Jerid Francom. It was last built on October 24, 2021 (latest version).</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
